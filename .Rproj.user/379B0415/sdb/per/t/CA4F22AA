{
    "contents" : "#'\n#' Reads a KEEL data format file or an ARFF data format file.\n#'\n#' This function reads a KEEL (.dat) or ARFF (.arff) dataset file and store the information\n#'   in a \\code{keel} class. This function also create fuzzy sets definitions for numeric variables\n#'   for execute in SDIGA, MESDIF, NMEEF-SD and FuGePSD algorithms\n#'\n#' @param file The path of the file in KEEL format\n#' @param nLabels The number of fuzzy labels to create on numerical variables.\n#'\n#' @details  A KEEL data file must have the following structure:\n#'  \\itemize{\n#'    \\item{ @@relation: Name of the data set }\n#'    \\item{ @@attribute: Description of an attribute (one for each attribute)}\n#'    \\item{ @@inputs: List with the names of the input attributes }\n#'    \\item{ @@output: Name of the output attribute (Not used in this algorithms implementation) }\n#'    \\item{ @@data: Starting tag of the data}\n#' }\n#'    The rest of the file contains all the examples belonging to the data set, expressed in comma sepparated values format.\n#' ARFF file format is a well-know dataset format from WEKA data mining tool.\n#' \n#' @author Angel M. Garcia <amgv0009@@red.ujaen.es> \n#'    \n#' @references J. Alcala-Fdez, A. Fernandez, J. Luengo, J. Derrac, S. Garcia, L. Sanchez, F. Herrera. KEEL Data-Mining Software Tool: Data Set Repository, Integration of Algorithms and Experimental Analysis Framework. Journal of Multiple-Valued Logic and Soft Computing 17:2-3 (2011) 255-287.\n#' \n#' @seealso KEEL Dataset Repository (Standard Classification): \\url{http://sci2s.ugr.es/keel/category.php?cat=clas}\n#'\n#' @examples\n#'     \\dontrun{\n#'        Reads a KEEL dataset from a file.\n#'        read.keel(file = \"C:\\KEELFile.dat\")\n#'\n#'        read.keel(file = \"C:\\KEELFile.dat\", nLabels = 7)\n#'        \n#'      Reads an ARFF dataset from a file.\n#'        read.keel(file = \"C:\\ARFFFile.arff\")\n#'\n#'        read.keel(file = \"C:\\ARFFFile.arff\", nLabels = 7)\n#'     }\n#'     \n#' @export\nread.keel <- function(file, nLabels = 3) {\n  if (nLabels < 1)\n    stop(\"Number of fuzzy sets ('nLabels') must be greater than zero.\")\n  if(length(file) > 1){\n    stop(paste(substitute(file), \"must be of length 1.\"))\n  }\n  #Detect extension\n  ext <- regmatches(x = file, m = gregexpr(pattern = \"\\\\.[[:alnum:]]+$\", text = file))[[1]]\n  \n  if(ext == \".dat\"){\n    data <- .readFile(file)\n    value <- which(data == \"@data\") - 1\n    if (length(value) == 0)\n      stop(\"No '@data' field found, this is not a KEEL format dataset. Aborting load...\")\n    properties <- data[1:value]\n    data <- data[(value + 2):length(data)]\n    \n    # Preparacion de las propiedades de los datos\n    \n    properties <- lapply(X = properties, FUN = .preprocessHeader)\n    \n    num_atribs <-\n      length(properties) - 3 # Obviamos valor de @relation, @inputs y @outputs\n    atribs_names <- character(num_atribs)\n    atribs_types <- character(num_atribs)\n    atribs_min <- numeric(num_atribs)\n    atribs_max <- numeric(num_atribs)\n    categorical_values <- vector(mode = \"list\", length = num_atribs)\n    \n    #Procesamos @relation\n    relation_pos <- grep(pattern = \"@relation\", x = properties, fixed = TRUE) #NOTA: Es mejor usar pmatch ! 77x faster!\n    if (length(relation_pos) == 0)\n      stop(\"No '@relation' field provided, this is not a KEEL format dataset. Aborting load... \")\n    relacion <- properties[[relation_pos]][2]\n    \n    #Procesamos el resto de atributos\n    atributes <- properties[-c(relation_pos, grep(pattern = \"@inputs|@output\", x = properties))]\n    aux <- vector(mode = \"list\", length = 5)\n    \n    if (length(atributes) == 0)\n      stop(\n        \"No '@input' or '@output' fields found, this is not a KEEL format dataset. Aborting load...\"\n      )\n    \n    for (i in seq_len(length(atributes))) {\n      aux <- .processLine(line = atributes[[i]])\n      \n      atribs_names[i] <- aux[[1]]\n      atribs_types[i] <- aux[[2]]\n      atribs_min[i] <- aux[[3]]\n      atribs_max[i] <- aux[[4]]\n      categorical_values[[i]] <- aux[[5]]\n    }\n    \n    \n    #Preparacion de los datos\n    if (Sys.info()[1] != \"Windows\")\n      data <-\n      parallel::mclapply(\n        X = data, FUN = .processData, categorical_values, atribs_types, mc.cores = parallel::detectCores() - 1\n      )\n    else\n      #In windows mclapply doesnt work\n      data <-\n      parallel::mclapply(\n        X = data, FUN = .processData, categorical_values, atribs_types, mc.cores = 1\n      )\n    \n    \n    #Preparacion del resto de atributos del dataset\n    \n    covered <- logical(length = length(data))\n    fuzzySets <-\n      .create_fuzzyIntervals(\n        min = atribs_min, max = atribs_max, num_sets = nLabels, types = atribs_types\n      )\n    crispSets <- .createCrispIntervals(fuzzyIntervals = fuzzySets)\n    classNames <- categorical_values[[length(categorical_values)]]\n    clValues <- unlist(lapply(data, '[', length(atributes)))\n    examplesPerClass <-\n      lapply(\n        X = seq_len(length(classNames)) - 1, FUN = function(x, data)\n          sum(data == x), clValues\n      )\n    names(examplesPerClass) <- classNames\n    \n    conjuntos <-\n      .dameConjuntos(data_types = atribs_types, max = atribs_max, n_labels = nLabels)\n    \n    lostData <- FALSE #Quitar esto\n    \n    lista <- list(\n      relation = relacion,\n      atributeNames = atribs_names,\n      atributeTypes = atribs_types,\n      min = atribs_min,\n      max = atribs_max,\n      nVars = length(atribs_min) - 1,\n      data = data,\n      class_names = classNames,\n      examplesPerClass = examplesPerClass,\n      lostData = lostData,\n      covered = covered,\n      fuzzySets = fuzzySets,\n      crispSets = crispSets,\n      conjuntos = conjuntos,\n      categoricalValues = categorical_values,\n      Ns = length(data)\n    )\n    \n    \n    class(lista) <- \"keel\"\n    lista\n  } else if(ext == \".arff\"){\n    keelFromARFF(file, nLabels)\n  } else {\n    stop(\"Invalid format. Valid formats are: '.arff' or '.dat'\")\n  }\n  \n}\n\n\n\n\n#\n#\n#  Reads a parameter file for an implemented algorithm\n#\n#\n.read.parametersFile2 <- function(file) {\n  data <- .readFile(file)\n \n  data <- strsplit(x = data, split = \" = \")\n  \n  \n  #Mirar posicion de los parametros\n  alg <- grep(pattern = \"algorithm\", x = data, fixed = TRUE)\n  iData <- grep(pattern = \"inputData\", x = data, fixed = TRUE)\n  oData <- grep(pattern = \"outputData\", x = data, fixed = TRUE)\n  seed <- grep(pattern = \"seed\", x = data, fixed = TRUE)\n  labels <- grep(pattern = \"nLabels\", x = data, fixed = TRUE)\n  evals <- grep(pattern = \"nEval\", x = data, fixed = TRUE)\n  len <- grep(pattern = \"popLength\", x = data, fixed = TRUE)\n  cross <- grep(pattern = \"crossProb\", x = data, fixed = TRUE)\n  mut <- grep(pattern = \"mutProb\", x = data, fixed = TRUE)\n  rep <- grep(pattern = \"RulesRep\", x = data, fixed = TRUE)\n  tC <- grep(pattern = \"targetClass\", x = data, fixed = TRUE)\n  #MESDIF Parametros\n  elit <- grep(pattern = \"eliteLength\", x = data, fixed = TRUE)\n  ech <- grep(pattern = \"echo\", x = data, fixed = TRUE)\n  #SDIGA Parametros\n  ob1 <- grep(pattern = \"Obj1\", x = data, fixed = TRUE)\n  ob2 <- grep(pattern = \"Obj2\", x = data, fixed = TRUE)\n  ob3 <- grep(pattern = \"Obj3\", x = data, fixed = TRUE)\n  ob4 <- grep(pattern = \"Obj4\", x = data, fixed = TRUE)\n  w1 <- grep(pattern = \"w1\", x = data, fixed = TRUE)\n  w2 <- grep(pattern = \"w2\", x = data, fixed = TRUE)\n  w3 <- grep(pattern = \"w3\", x = data, fixed = TRUE)\n  search <- grep(pattern = \"lSearch\", x = data, fixed = TRUE)\n  miConf <- grep(pattern = \"minConf\", x = data, fixed = TRUE)\n  #NMEEF-SD Parametros\n  div <- grep(pattern = \"diversity\", x = data, fixed = TRUE)\n  rInit <- grep(pattern = \"ReInitCob\", x = data, fixed = TRUE)\n  pCob <- grep(pattern = \"porcCob\", x = data, fixed = TRUE)\n  dom <- grep(pattern = \"StrictDominance\", x = data, fixed = TRUE)\n  miCf <- grep(pattern = \"minCnf\", x = data, fixed = TRUE)\n  #FuGePSD Parametros\n  nLabels <- grep(pattern = \"Number of Labels\", x = data, fixed = TRUE)\n  tnorm <- grep(pattern = \"T-norm/T-conorm for the Computation of the Compatibility Degree\", x = data, fixed = TRUE)\n  ruleWeight <- grep(pattern = \"Rule Weight\", x = data, fixed = TRUE)\n  frm <- grep(pattern = \"Fuzzy Reasoning Method\", x = data, fixed = TRUE)\n  numGens <- grep(pattern = \"Number of Generations\", x = data, fixed = TRUE)\n  tamPop <- grep(pattern = \"Initial Number of Fuzzy Rules\", x = data, fixed = TRUE)\n  crossProb <- grep(pattern = \"Crossover probability\", x = data, fixed = TRUE)\n  mutProb <- grep(pattern = \"Mutation probability\", x = data, fixed = TRUE)\n  insProb <- grep(pattern = \"Insertion probability\", x = data, fixed = TRUE)\n  dropProb <- grep(pattern = \"Dropping Condition probability\", x = data, fixed = TRUE)\n  tsSize <- grep(pattern = \"Tournament Selection Size\", x = data, fixed = TRUE)\n  gfw1 <- grep(pattern = \"Global Fitness Weight 1\", x = data, fixed = TRUE)\n  gfw2 <- grep(pattern = \"Global Fitness Weight 2\", x = data, fixed = TRUE)\n  gfw3 <- grep(pattern = \"Global Fitness Weight 3\", x = data, fixed = TRUE)\n  gfw4 <- grep(pattern = \"Global Fitness Weight 4\", x = data, fixed = TRUE)\n  allClass <- grep(pattern = \"All Class\", x = data, fixed = TRUE)\n  #--------------------------------------------------------\n  \n  if (length(alg) == 0)\n    stop(\"Param file error: 'algorithm' not especified. \")\n  algoritmo <- data[[alg]][2]\n  if (length(iData) == 0)\n    stop(\"Param file error: 'inputData' not especified. \")\n  if (length(oData) == 0)\n    stop(\"Param file error: 'outputData' not especified. \")\n  if (length(seed) == 0)\n    stop(\"Param file error: 'seed' not especified. \")\n  \n  if(any(algoritmo == c(\"SDIGA\", \"MESDIF\", \"NMEEFSD\"))){\n    if (length(labels) == 0)\n      stop(\"Param file error: 'nLabels' not especified. \")\n    if (length(evals) == 0)\n      stop(\"Param file error: 'nEval' not especified. \")\n    if (length(len) == 0)\n      stop(\"Param file error: 'popLength' not especified. \")\n    if (length(cross) == 0)\n      stop(\"Param file error: 'crossProb' not especified. \")\n    if (length(mut) == 0)\n      stop(\"Param file error: 'mutProb' not especified. \")\n    if (length(rep) == 0)\n      stop(\"Param file error: 'RulesRep' not especified. \")\n    if (length(tC) == 0)\n      stop(\"Param file error: 'targetClass' not especified. \")\n  }\n\n  if (!any(algoritmo == c(\"SDIGA\", \"MESDIF\", \"NMEEFSD\", \"FUGEPSD\")))\n    stop(\"Param file error: 'Algorithm' must be \\\"SDIGA\\\", \\\"MESDIF\\\", \\\"NMEEFSD\\\" or \\\"FUGEPSD\\\"  \")\n  \n  #General parameters\n  #datos de entrada\n  input_data <- character(2) # Dos inputs, training y tes\n  \n  input_string <-\n    gsub(\n      pattern = '\\\"', replacement = \"\", x = data[[iData]][2], fixed = TRUE\n    )\n  input_data <-\n    strsplit(x = input_string, split = \" \", fixed = TRUE)[[1]]\n  \n  output_data <- character(4) # Reglas, tra_qua, tra_seg y tst_quac\n  \n  input_string <-\n    gsub(\n      pattern = '\\\"', replacement = \"\", x = data[[oData]][2], fixed = TRUE\n    )\n  output_data <-\n    strsplit(x = input_string, split = \" \", fixed = TRUE)[[1]]\n  \n  semilla <- as.integer(data[[seed]][2])\n  \n  if(length(input_data) > 2){ #If the are more than 2 input files we warning the user.\n    warning(\"More than two input files have been specified. Only the first two will be used !\")\n  }\n  \n  if(any(algoritmo == c(\"SDIGA\", \"MESDIF\", \"NMEEFSD\"))){\n    n_intervals <- as.integer (data[[labels]][2])\n    n_evals <- as.integer (data[[evals]][2])\n    popLenght <- as.integer(data[[len]][2])\n    crossProb <- as.double(data[[cross]][2])\n    prob_mutacion <- as.double(data[[mut]][2])\n    rule_type <- data[[rep]][2]\n    target <- data[[tC]][2]\n  }\n  \n  #SDIGA own parameters\n  if (algoritmo == \"SDIGA\") {\n    if (length(miConf) == 0)\n      stop(\"Param file error: 'minConf' not specified.\")\n    if (length(ob1) == 0)\n      stop(\"Param file error: 'Obj1' not specified.\")\n    if (length(ob2) == 0)\n      stop(\"Param file error: 'Obj2' not specified.\")\n    if (length(ob3) == 0)\n      stop(\n        \"Param file error: 'Obj3' not specified (If you dont want specify, you must write null).\"\n      )\n    if (length(w1) == 0)\n      stop(\"Param file error: 'w1' not specified.\")\n    if (length(w2) == 0)\n      stop(\"Param file error: 'w2' not specified.\")\n    if (length(w3) == 0)\n      stop(\"Param file error: 'w3' not specified.\")\n    if (length(search) == 0)\n      stop(\"Param file error: 'localSearch' not specified.\")\n    \n    minimun_confidence <- as.double(data[[miConf]][2])\n    Obj1 <- data[[ob1]][2]\n    Obj2 <- data[[ob2]][2]\n    Obj3 <- data[[ob3]][2]\n    peso1 <- as.double(data[[w1]][2])\n    peso2 <- as.double(data[[w2]][2])\n    peso3 <- as.double(data[[w3]][2])\n    local_search <- data[[search]][2]\n    \n    lista <-\n      list(\n        algorithm = algoritmo, inputData = input_data, outputData = output_data, seed = semilla, nLabels = n_intervals, nEval = n_evals, popLength = popLenght, crossProb = crossProb, mutProb = prob_mutacion, minConf = minimun_confidence, RulesRep = rule_type, Obj1 = Obj1, Obj2 = Obj2, Obj3 = Obj3, w1 = peso1, w2 = peso2, w3 = peso3, lSearch = local_search, targetClass = target\n      )\n    \n  }\n  \n  #MESDIF own parameters\n  if (algoritmo == \"MESDIF\") {\n    if (length(elit) == 0)\n      stop(\"Param file error: 'elitePop' not specified.\")\n    if (length(ech) == 0)\n      stop(\"Param file error: 'echo' not specified.\")\n    if (length(ob1) == 0)\n      stop(\"Param file error: 'Obj1' not specified.\")\n    if (length(ob2) == 0)\n      stop(\"Param file error: 'Obj2' not specified.\")\n    if (length(ob3) == 0)\n      stop(\n        \"Param file error: 'Obj3' not specified (If you dont want specify, you must write null).\"\n      )\n    if (length(ob4) == 0)\n      stop(\n        \"Param file error: 'Obj4' not specified (If you dont want specify, you must write null).\"\n      )\n    \n    \n    elite <- as.numeric(data[[elit]][2])\n    echo <- data[[ech]][2]\n    Obj1 <- data[[ob1]][2]\n    Obj2 <- data[[ob2]][2]\n    Obj3 <- data[[ob3]][2]\n    Obj4 <- data[[ob4]][2]\n    \n    \n    lista <-\n      list(\n        algorithm = algoritmo, inputData = input_data, outputData = output_data, seed = semilla, nLabels = n_intervals, nEval = n_evals, popLength = popLenght, crossProb = crossProb, mutProb = prob_mutacion, RulesRep = rule_type, targetClass = target, elitePop = elite, echo = echo, Obj1 = Obj1, Obj2 = Obj2, Obj3 = Obj3, Obj4 = Obj4\n      )\n    \n  }\n  \n  #NMEEF-SD own parameters\n  if (algoritmo == \"NMEEFSD\") {\n    #if(length(div) == 0) stop(\"Param file error: 'diversity' not specified.\")\n    if (length(rInit) == 0)\n      stop(\"Param file error: 'ReInitCob' not specified.\")\n    if (length(pCob) == 0)\n      stop(\"Param file error: 'porcCob' not specified.\")\n    if (length(dom) == 0)\n      stop(\"Param file error: 'StrictDominance' not specified.\")\n    if (length(miCf) == 0)\n      stop(\"Param file error: 'minCnf' not specified.\")\n    \n    diversity <- data[[div]][2]\n    reInit <- data[[rInit]][2]\n    porcCob <- data[[pCob]][2]\n    dominance <- data[[dom]][2]\n    minConf <- data[[miCf]][2]\n    Obj1 <- data[[ob1]][2]\n    Obj2 <- data[[ob2]][2]\n    Obj3 <- data[[ob3]][2]\n    \n    lista <-\n      list(\n        algorithm = algoritmo, inputData = input_data, outputData = output_data, seed = semilla, nLabels = n_intervals, nEval = n_evals, popLength = popLenght, crossProb = crossProb, mutProb = prob_mutacion, RulesRep = rule_type, targetClass = target, StrictDominance = dominance, diversity = diversity, porcCob = porcCob, reInitPob = reInit, minConf = minConf, Obj1 = Obj1, Obj2 = Obj2, Obj3 = Obj3\n      )\n    \n  }\n  \n  \n  #FuGePSD Own Parameters\n  if(algoritmo == \"FUGEPSD\"){\n    if(length(nLabels) == 0)\n      stop(\"'Number of Labels' not specified.\")\n    if(length(tnorm) == 0)\n      stop(\"'T-norm/T-conorm for the Computation of the Compatibility Degree' not specified\")\n    if(length(ruleWeight) == 0)\n      stop(\"'Rule Weight' not specified.\")\n    if(length(frm) == 0)\n      stop(\"'Fuzzy Reasoning Method' not specified.\")\n    if(length(numGens) == 0)\n      stop(\"'Number of Generations' not specified.\")\n    if(length(tamPop) == 0)\n      stop(\"'Initial Number of Fuzzy Rules (0 for 5*n_var)' not specified.\")\n    if(length(crossProb) == 0)\n      stop(\"'Crossover probability' not specified.\")\n    if(length(mutProb) == 0)\n      stop(\"'Mutation probability' not specified.\")\n    if(length(insProb) == 0)\n      stop(\"'Insertion probability' not specified.\")\n    if(length(dropProb) == 0)\n      stop(\"'Dropping Condition probability' not specified.\")\n    if(length(tsSize) == 0)\n      stop(\"'Tournament Selection Size' not specified.\")\n    if(length(gfw1) == 0)\n      stop(\"'Global Fitness Weight 1' not specified.\")\n    if(length(gfw2) == 0)\n      stop(\"'Global Fitness Weight 2' not specified.\")\n    if(length(gfw3) == 0)\n      stop(\"'Global Fitness Weight 3' not specified.\")\n    if(length(gfw4) == 0)\n      stop(\"'Global Fitness Weight 4' not specified.\")\n    if(length(allClass) == 0)\n      stop(\"'All Class' not specified.\")\n  \n    \n    lista <- list(algorithm = algoritmo, \n                  inputData = input_data, \n                  outputData = output_data, \n                  seed = semilla, \n                  nLabels = as.integer(data[[nLabels]][2]), \n                  nGens = as.integer(data[[numGens]][2]), \n                  popLength = as.integer(data[[tamPop]][2]), \n                  crossProb = as.double(data[[crossProb]][2]), \n                  mutProb = as.double(data[[mutProb]][2]),\n                  insPro = as.double(data[[insProb]][2]),\n                  dropProb = as.double(data[[dropProb]][2]),\n                  frm = tolower(data[[frm]][2]),\n                  tnorm = tolower(data[[tnorm]][2]),\n                  ruleWeight = tolower(data[[ruleWeight]][2]),\n                  tournamentSize = as.integer(data[[tsSize]][2]),\n                  allClass = data[[allClass]][2],\n                  alphaFitness = 0,\n                  executionType = 1,\n                  gfw1 = as.double(data[[gfw1]][2]),\n                  gfw2 = as.double(data[[gfw2]][2]),\n                  gfw3 = as.double(data[[gfw3]][2]),\n                  gfw4 = as.double(data[[gfw4]][2])\n      )\n    \n  }\n  \n  lista\n  \n}\n\n#---------------------------------------------------------------------------\n# Shows information about parameters\n# --------------------------------------------------------------------------\n\n.show_parameters <- function(params, train, test) {\n  #Show parameters in the console\n  algo <- params$algorithm\n  cat(\n    \"--------------------------------\", file = \"\", sep = \" \", fill = TRUE\n  )\n  cat(\"Algorithm:\", algo, file = \"\", sep = \" \", fill = TRUE)\n  cat(\n    \"Relation:\", train$relation, file = \"\", sep = \" \", fill = TRUE\n  )\n  cat(\n    \"Training file:\", params$inputData[1], file = \"\", sep = \" \", fill = TRUE\n  )\n  cat(\n    \"Test file:\", params$inputData[2], file = \"\", sep = \" \", fill = TRUE\n  )\n  cat(\n    \"Rules Representation: \", if (tolower(params$RulesRep) == \"can\")\n      \"CAN\"\n    else\n      \"DNF\", file = \"\", sep = \" \", fill = TRUE\n  )\n  cat(\n    \"Number of evaluations:\", params$nEval, file = \"\", sep = \" \", fill = TRUE\n  )\n  cat(\n    \"Number of fuzzy partitions:\", params$nLabels, file = \"\", sep = \" \", fill = TRUE\n  )\n  cat(\n    \"Population Length:\", params$popLength, file = \"\", sep = \" \", fill = TRUE\n  )\n  if (algo == \"MESDIF\")\n    cat(\n      \"Elite Population Length:\", params$elitePop, file = \"\", sep = \" \", fill = TRUE\n    )\n  if (algo != \"SDIGA\")\n    cat(\n      \"Crossover Probability:\", params$crossProb, file = \"\", sep = \" \", fill = TRUE\n    )\n  cat(\n    \"Mutation Probability:\", params$mutProb, file = \"\", sep = \" \", fill = TRUE\n  )\n  cat(\n    \"Obj1:\", params$Obj1, \"  (Weigth:\", params$w1,\")\", file = \"\", sep = \" \", fill = TRUE\n  )\n  cat(\n    \"Obj2:\", params$Obj2, \"  (Weigth:\", params$w2,\")\", file = \"\", sep = \" \", fill = TRUE\n  )\n  cat(\n    \"Obj3:\", params$Obj3, \"  (Weigth:\", params$w3,\")\", file = \"\", sep = \" \", fill = TRUE\n  )\n  if (algo == \"MESDIF\")\n    cat(\"Obj4:\", params$Obj4, file = \"\", sep = \" \", fill = TRUE)\n  if (algo == \"SDIGA\")\n    cat(\n      \"Local Search optimization?:\", params$lSearch, file = \"\", sep = \" \", fill = TRUE\n    )\n  if (algo == \"NMEEFSD\") {\n    cat(\n      \"Reinitilization based on coverage?: \", params$reInitPob, file = \"\", fill = TRUE\n    )\n    cat(\n      \"Max Pct of variables in reinitialization: \", as.numeric(params$porcCob) * 100, \"%\", file = \"\", fill = TRUE\n    )\n    cat(\n      \"Compare individuals using strict dominance? \", params$StrictDominance, file = \"\", fill = TRUE\n    )\n  }\n  cat(\n    \"Number of examples in training:\", train$Ns, file = \"\", sep = \" \", fill = TRUE\n  )\n  cat(\n    \"Number of examples in test:\", test$Ns, file = \"\", sep = \" \", fill = TRUE\n  )\n  cat(\n    \"--------------------------------\", file = \"\", sep = \" \", fill = TRUE\n  )\n  \n  \n  #Save parameters in the outputFile\n  algo <- params$algorithm\n  cat(\n    \"--------------------------------\" , \"\\n\",\n    \"Algorithm:\",algo ,\"\\n\",\n    \"Relation:\", train$relation, \"\\n\",\n    \"Training file:\", params$inputData[1], \"\\n\",\n    \"Test file:\", params$inputData[2], \"\\n\",\n    \"Rules Representation: \", if (tolower(params$RulesRep) == \"can\")\n      \"CAN\"\n    else\n      \"DNF\", \"\\n\",\n    \"Number of evaluations:\", params$nEval,\"\\n\",\n    \"Number of fuzzy partitions:\", params$nLabels, \"\\n\",\n    \"Population Length:\", params$popLength, \"\\n\",\n    if (algo == \"MESDIF\")\n      paste(\"Elite Population Length:\", params$elitePop, \"\\n\"),\n    if (algo != \"SDIGA\")\n      paste(\"Crossover Probability:\", params$crossProb, \"\\n\"),\n    \"Mutation Probability:\", params$mutProb, \"\\n\",\n    paste(\"Obj1:\", params$Obj1, \"  (Weigth:\", params$w1,\")\", \"\\n\"),\n    paste(\"Obj2:\", params$Obj2, \"  (Weigth:\", params$w2,\")\", \"\\n\"),\n    paste(\"Obj3:\", params$Obj3, \"  (Weigth:\", params$w3,\")\", \"\\n\"),\n    if (algo == \"MESDIF\")\n      paste(\"Obj4:\", params$Obj4, \"\\n\"),\n    if (algo == \"SDIGA\")\n      paste(\"Local Search optimization?:\", params$lSearch, \"\\n\"),\n    if (algo == \"NMEEFSD\") {\n      paste(\n        \"Reinitilization based on coverage?: \", params$reInitPob, \"\\n\",\n        \"Max Pct of variables in reinitialization: \", as.numeric(params$porcCob) * 100, \"%\", \"\\n\",\n        \"Compare individuals using strict dominance? \", params$StrictDominance, \"\\n\"\n      )\n    },\n    \"Number of examples in training:\", train$Ns, \"\\n\",\n    \"Number of examples in test:\", test$Ns, \"\\n\",\n    \"--------------------------------\", file = params$outputData[1], sep = \" \"\n  )\n  \n}\n\n\n#\n#@name .dameConjuntos\n#@description Devuelve el numero de conjuntos (difusos o no) en funci?n del tipo de par?metro.\n#   Si son datos continuos da como resultado el numero de conjuntos difusos.\n#   En caso de ser categoricos devolvera el numero de categorias\n#\n\n\n.dameConjuntos <- function(data_types, max, n_labels) {\n  data_types <- data_types[-length(data_types)]\n  \n  salida <- numeric(length(data_types))\n  cat <- which(data_types == 'c')\n  if (length(cat > 0)) {\n    #Si no hay datos categoricos, todos tienen el valor de n_labels\n    salida[cat] <- max[cat]\n    salida[-cat] <- n_labels\n  } else {\n    salida[] <- n_labels\n  }\n  salida\n  \n}\n\n\n\n#\n#\n# This function prints a rule for show to the user\n#\n#\n.print.rule <-\n  function(rule, max, names, consecuente, types, fuzzySets, categoricalValues, DNFRules = FALSE, rulesFile = \"rulesFile.txt\") {\n    if (!DNFRules) {\n      participantes <- which(rule < max)\n      nombre <- names[participantes]\n      valores <- rule[participantes]\n      types <- types[participantes]\n      fuzzy <- fuzzySets[,,participantes, drop = F]\n      cate <- categoricalValues[participantes]\n      \n      val <- replicate(n = length(participantes), expr = NA)\n      \n      \n      for (p in seq_len(length(participantes))) {\n        if (types[p] == 'c') {\n          val[p] <- cate[[p]][valores[p] + 1]\n        } else {\n          val[p] <-\n            paste(\"Label\", valores[p], \"(\", fuzzy[valores[p] + 1,1,p], \",\", fuzzy[valores[p] +\n                                                                                    1,2,p], \",\",fuzzy[valores[p] + 1,3,p], \")\", sep = \" \")\n        }\n      }\n      nombre <- paste(\"Variable\", nombre, sep = \" \")\n      lineas <- paste(nombre, val, sep = \" = \")\n      lineas <- paste(lineas, collapse = \"\\n\")\n      cat(\n        lineas, \"\\n\",\"THEN\", consecuente, file = \"\", sep = \" \", fill = TRUE\n      )\n      \n      #Save in file\n      cat(\n        lineas, \"\\n\",\"THEN\", consecuente, file = rulesFile, sep = \" \", fill = TRUE, append = TRUE\n      )\n      \n    } else {\n      #Print DNF rule\n      \n      max <- Reduce(f = '+', x = max, accumulate = TRUE)\n      \n      anterior <- 1\n      pos <- 1\n      lineas <- \"\"\n      for (i in max) {\n        variable <- rule[anterior:i]\n        noParticipa <- all(variable == 1) | all(variable == 0)\n        if (!noParticipa) {\n          valores <- which(variable == 1)\n          nombreVariable <- names[pos]\n          if (types[pos] == 'c') {\n            nombresValores <- categoricalValues[[pos]][valores]\n            nombresValores <-\n              paste(nombresValores, sep = \" \", collapse = \" OR \")\n          } else {\n            nombresValores <-\n              paste(\n                \"Label\", valores - 1, \"(\", fuzzySets[valores,1,pos], \",\", fuzzySets[valores,2,pos], \",\",fuzzySets[valores,3,pos], \")\", sep = \" \", collapse = \" OR \"\n              )\n          }\n          lineas <-\n            paste(lineas, \"Variable\", nombreVariable, nombresValores, \"\\n\", sep = \" \")\n          \n          \n        }\n        pos <- pos + 1\n        anterior <- i + 1\n      }\n      cat(\n        lineas, \"\\n\",\"THEN\", consecuente, file = \"\", sep = \" \", fill = TRUE\n      )\n      #Save in file\n      cat(\n        lineas, \"\\n\",\"THEN\", consecuente, file = rulesFile, sep = \" \", fill = TRUE, append = TRUE\n      )\n      \n    }\n  }\n\n\n\n\n#\n#\n# Function to get the name of the objective value in the parameters file\n# and return the corresponding functions.\n#\n#\n.parseObjetives <- function(parametros, algorithm, DNF) {\n  Objetivos <- list(NA,NA,NA,NA) # prealocamos memoria\n  \n  if (algorithm == \"SDIGA\") {\n    if (parametros$Obj1 == \"CSUP\") {\n      #NO PONEMOS COMPLETITUD !!\n      Objetivos[[1]] <- .LocalSupport\n      Objetivos[[4]] <- FALSE\n    } else{\n      Objetivos[[1]] <- .FLocalSupport\n      Objetivos[[4]] <- TRUE\n    }\n    \n    if (parametros$Obj2 == \"CCNF\") {\n      Objetivos[[2]] <- .confianza\n    } else{\n      Objetivos[[2]] <- .confianzaDifusa\n    }\n    \n    if (parametros$Obj3 == \"UNUS\") {\n      Objetivos[[3]] <- .norm_unusualness\n    } else if (parametros$Obj3 == \"SIGN\") {\n      Objetivos[[3]] <- .significance\n    } else if (parametros$Obj3 == \"COVE\") {\n      Objetivos[[3]] <- .coverage\n    }\n    \n  } else {\n    valores <- c(parametros$Obj1, parametros$Obj2, parametros$Obj3)\n    \n    for (i in seq_len(3)) {\n      if (valores[i] == \"CSUP\")\n        Objetivos[[i]] <- .Csupport\n      if (valores[i] == \"FSUP\")\n        Objetivos[[i]] <- .Fsupport\n      if (valores[i] == \"CCNF\")\n        Objetivos[[i]] <- .confianza\n      if (valores[i] == \"FCNF\")\n        Objetivos[[i]] <- .confianzaDifusa\n      if (valores[i] == \"UNUS\")\n        Objetivos[[i]] <- .norm_unusualness\n      if (valores[i] == \"SIGN\")\n        Objetivos[[i]] <- .significance\n      if (valores[i] == \"COVE\")\n        Objetivos[[i]] <- .coverage\n      \n    }\n    \n    Objetivos[[4]] <- DNF\n  }\n  return(Objetivos)\n}\n\n\n\n\n#\n#\n# Preprocessing of a single line in the header of the KEEL file.\n#\n#\n.preprocessHeader <- function(line) {\n  #The regular expression eliminate eliminate the \"{}\" and \"[]\" symbols and commas that separate every element inside them\n  regex <-  \"[[:blank:]]*\\\\{|[[:blank:]]*\\\\}|[[:blank:]]*\\\\[|[[:blank:]]*\\\\]|,[[:blank:]]*\" \n  line <- gsub(pattern = regex, replacement = \" \", x = line)\n  \n  #Return\n  strsplit(line, \" \", fixed = TRUE)[[1]]\n  \n}\n\n\n\n#\n#\n# This function parses all examples in the @data field\n#\n#\n.processData <- function(data, categoricalValues, types, fromDataFrame = FALSE) {\n  line <- data\n  if(!fromDataFrame){\n    line <- gsub(pattern = \",[[:blank:]]*\", replacement = \" \", x = line)\n    line <- strsplit(x = line, split = \" \",fixed = TRUE)[[1]]\n  }\n  cat <- which(types == 'c')\n  lc <- line[cat]\n  cv <- categoricalValues[cat]\n  for (i in seq_len(length(lc))) {\n    pos <- which(cv[[i]] == lc[i])\n    if (length(pos) > 0) {\n      lc[i] <- pos - 1\n    } else{\n      #LostData\n      lc[i] <- length(cv[[i]]) + 1\n    }\n  }\n  line[cat] <- lc\n  \n  #Return\n  as.numeric(line)\n}\n\n\n# Devuelve una lista con los siguientes valores:\n# - Nombre del atributo\n# - tipo\n# - minimo\n# - maximo\n# - valores categoricos si los tuviera, NA en caso contrario\n.processLine <- function(line) {\n  returnList <- vector(mode = \"list\", length = 5)\n  returnList[[1]] <- line[2] # Attribute name\n  \n  if (line[3] != \"real\" & line[3] != \"integer\") {\n    # Dato categorico\n    returnList[[2]] <- 'c' # Attribute type\n    returnList[[3]] <- 0   #Minimum\n    returnList[[4]] <-\n      length(line) - 2 #Maximun number of categorical values\n    returnList[[5]] <- line[3:length(line)]\n    \n  } else {\n    #Numerical Values\n    returnList[[2]] <- if (line[3] == \"integer\")\n      'e'\n    else\n      'r'\n    returnList[[3]] <- as.numeric(line[4])\n    returnList[[4]] <- as.numeric(line[5])\n    returnList[[5]] <- NA\n  }\n  \n  returnList\n}\n\n\n\n\n#\n#\n# This function reads an entire file in a block and the it is splitted by the \\n or \\r character.\n# It is 8X faster than using scan()\n#\n# Thanks to F. Charte! \n#\n.readFile <- function(file) {\n  con <- file(file, \"rb\")\n  if(!isOpen(con))\n    open(con, \"rb\")\n  \n  contents <- readChar(con, file.info(file)$size, useBytes = TRUE)\n  close(con)\n  \n  #Return\n  strsplit(x = contents, split = \"\\\\\\r\\n|\\\\\\r|\\\\\\n\", fixed = FALSE, useBytes = TRUE)[[1]]\n \n}\n\n\n#' Saves a \\code{keel} dataset into a KEEL dataset format file.\n#'\n#' This function exports a keel dataset stored in the R environment into a KEEL format file on the hard disk.\n#' This function can not save information about the fuzzy\n#' definition created by the function \\link{read.keel} because the KEEL format does not\n#' define that kind of information.\n#'\n#' @param dataset The \\code{keel} object stored in R environment.\n#' @param file The file name (or path) to save the KEEL dataset.\n#'\n#' @details  A KEEL data file must have the following structure:\n#'  \\itemize{\n#'    \\item{ @@relation: Name of the data set }\n#'    \\item{ @@attribute: Description of an attribute (one for each attribute)}\n#'    \\item{ @@inputs: List with the names of the input attributes }\n#'    \\item{ @@output: Name of the output attribute (Not used in this algorithms implementation) }\n#'    \\item{ @@data: Starting tag of the data}\n#' }\n#'    The rest of the file contains all the examples belonging to the data set, expressed in comma sepparated values format.\n#'\n#' @author Angel M. Garcia <amgv0009@@red.ujaen.es>\n#'\n#' @references J. Alcala-Fdez, A. Fernandez, J. Luengo, J. Derrac, S. Garcia, L. Sanchez, F. Herrera. KEEL Data-Mining Software Tool: Data Set Repository, Integration of Algorithms and Experimental Analysis Framework. Journal of Multiple-Valued Logic and Soft Computing 17:2-3 (2011) 255-287.\n#' @seealso KEEL Dataset Repository (Standard Classification): \\url{http://sci2s.ugr.es/keel/category.php?cat=clas}\n#' \n#' \nsave.keel <- function(dataset, file) {\n  #First, we need to ask the user if he want to save the file\n  \n  if (is.null(file) | is.na(file) | missing(file)) {\n    stop(\"Parameter 'file' can not be NULL or NA.\")\n  }\n  \n  if (length(file) > 1) {\n    stop(\"'file' must be of length 1.\")\n  }\n  \n  if (class(dataset) != \"keel\") {\n    stop(\"'dataset' must be of class 'keel'.\")\n  }\n  \n  respuesta <-\n    .yesno(\"Do you really want to save this dataset? (y/n): \")\n  \n  if (respuesta == \"y\") {\n    #Add .dat extension to the file.\n    file <- paste(file, \".dat\", sep = \"\")\n    #Save file\n    #get relation name\n    cat(\"Getting attributes...\")\n    line <- paste(\"@relation\", dataset[[1]])\n    \n    #get attributes\n    aux <- character(length(dataset[[2]]))\n    aux[which(dataset[[3]] == \"e\")] <- \"integer\"\n    aux[which(dataset[[3]] == \"r\")] <- \"real\"\n    pos <- which(dataset[[3]] == \"c\")\n    aux_values <- character(length(dataset[[2]]))\n    aux_values[pos] <- dataset$categoricalValues[pos]\n    aux_values[-pos] <-\n      paste(\"[\",dataset$min[-pos], \", \", dataset$max[-pos], \"] \", sep = \"\")\n    a <- lapply(aux_values, function(x)\n      if (length(x) > 1) {\n        aux <- paste(x , collapse = \", \")\n        paste(\"{\", aux, \"}\", sep = \"\")\n      } else{\n        x\n      })\n    a <- unlist(a)\n    \n    atributos <- paste(\"@attribute\", dataset$atributeNames, aux, a)\n    atributos <- paste(atributos, collapse = \"\\n\")\n    \n    line <- paste(line, atributos, sep = \"\\n\")\n    \n    #get inputs and outputs\n    inputs <-\n      paste(dataset[[2]][-length(dataset[[2]])], collapse = \", \")\n    output <- dataset[[2]][length(dataset[[2]])]\n    line <- paste(line, \"\\n\", \"@inputs \", inputs, \"\\n\", sep = \"\")\n    line <- paste(line, \"@outputs \", output, \"\\n@data\",  sep = \"\")\n    cat(\"Done\\nGetting data (this may take some time)...\")\n    \n    #get data\n    categ <- which(dataset[[3]] == \"c\")\n    if (Sys.info()[1] != \"Windows\") {\n      data <-\n        parallel::mclapply(\n          X = dataset$data, FUN = function(x, pos, catValues) {\n            resultado <-\n              lapply(\n                X = seq_len(length(pos)), FUN = function(y, pos, data) {\n                  data[pos[y]] <- catValues[[pos[y]]][data[pos[y]] + 1]\n                  data[pos[y]]\n                }, categ, x\n              )\n            x[pos] <- resultado\n            unlist(x)\n          }, categ, dataset$categoricalValues, mc.cores = parallel::detectCores() - 1\n        )\n    } else {\n      data <- lapply(\n        X = dataset$data, FUN = function(x, pos, catValues) {\n          resultado <-\n            lapply(\n              X = seq_len(length(pos)), FUN = function(y, pos, data) {\n                data[pos[y]] <- catValues[[pos[y]]][data[pos[y]] + 1]\n                data[pos[y]]\n              }, categ, x\n            )\n          x[pos] <- resultado\n          unlist(x)\n        }, categ, dataset$categoricalValues\n      )\n    }\n    \n    \n    #Paste data into the line\n    data <- lapply(data, function(x) {\n      paste(x, collapse = \", \")\n    })\n    \n    data <- unlist(data)\n    line <- paste(line, paste(data, collapse = \"\\n\"), sep = \"\\n\")\n    cat(\"Done\\n\")\n    \n    #Save file\n    cat(line, file = file,  sep = \"\", append = FALSE)\n    cat(\"File succesfully saved.\")\n  } else {\n    cat(\"File not saved.\")\n  }\n}\n\n\n#'\n#' Add one or a set of instances to a KEEL dataset.\n#'\n#' Take a data vector or a list of data vectors and inserts at the end of a \\code{keel} data set.\n#' \n#' @param items Vector or list of instance/s\n#' @param dataset The \\code{keel} dataset to insert the data.\n#' \n#' @details You can add the data in four ways:\n#' \\itemize{\n#'  \\item A single element, using a vector.\n#'    \\itemize{\n#'      \\item Coded.\n#'      \\item Uncoded.\n#'    }\n#'  \\item More than one element, using a list of vectors.\n#'   \\itemize{\n#'      \\item Coded.\n#'      \\item Uncoded.\n#'    }\n#' }\n#' \n#' Coded means that vectors of data are all numeric (including class) and, obviously, \n#' all values are within the bounds stablished. This way is the returned after a \\code{read.keel()} call\n#' and it is the ideal for introduce data from one dataset to another, for example.\n#' \n#'  Uncoded means that vectors of data are characters, because it has at least one value that is a string (class value) and values are valid. This is common when we read\n#'  a csv file or we introduce data manually, for example.   \n#' \n#' @return Returns the new dataset with data introduced. This dataset is a list with a vectors of every instace.  \n#' This dataset should be stored into the \\code{$data}\n#' field of a \\code{keel} class variable.\n#' \n#' @author Angel M. Garcia <amgv0009@@red.ujaen.es>\n#'\n#' @references J. Alcala-Fdez, A. Fernandez, J. Luengo, J. Derrac, S. Garcia, L. Sanchez, F. Herrera. KEEL Data-Mining Software Tool: Data Set Repository, Integration of Algorithms and Experimental Analysis Framework. Journal of Multiple-Valued Logic and Soft Computing 17:2-3 (2011) 255-287.\n#' @seealso KEEL Dataset Repository (Standard Classification): \\url{http://sci2s.ugr.es/keel/category.php?cat=clas}\n#'\n#' \naddKeelRegister <- function(items, dataset) {\n  if (class(dataset) != \"keel\") {\n    stop(\"Provided dataset is not of class 'keel'.\")\n  }\n  \n  \n  # If items is not a list, is a single element.\n  if (class(items) != \"list\") {\n    if (.checkElement(item = items, dataset = dataset)) {\n      #We use this because it is only a single element !\n      if (class(items) == \"numeric\") {\n        dataset$data[[length(dataset$data) + 1]] <- items\n        dataset$data\n      } else {\n        items <- paste(items, collapse = \", \")\n        items <- .processData(items, dataset$categoricalValues, dataset$atributeTypes)\n        \n        dataset$data[[length(dataset$data) + 1]] <- items\n        dataset$data\n      }\n    } else {\n      stop(\"Adding an invalid element into the dataset.\")\n    }\n    \n  } else {\n    #If it is a list, there are more than one item, add it efficiently.\n    resultDataset <- vector(mode = \"list\", length = length(dataset$data) + length(items))\n    \n    #Copy old data to the new list\n    resultDataset[seq_len(length(dataset$data))] <- dataset$data\n    \n    #Check if all new data are correct.\n    allElements <- unlist(lapply(X = items, FUN = .checkElement, dataset))\n    \n    if (all(allElements)) {\n      if (class(items[[1]]) == \"character\") {\n        #Process the elements, tranform every vector into a string line to use the .processData() function.\n        items <- lapply(items, paste, collapse = \", \")\n        items <- lapply(items, .processData, dataset$categoricalValues, dataset$atributeTypes)\n      }\n      #Introduce the elements at the end of the $data atribute of the dataset.\n      resultDataset[(length(dataset$data) + 1):length(resultDataset)] <-\n        items\n      \n      #Return\n      resultDataset\n    } else {\n      stop(\"One or more new items are invalid. No items added.\")\n    }\n  }\n  \n}\n\n\n\n\n\n\n#Checks if a single instance has correct data.\n.checkElement <- function(item, dataset) {\n  #Check lengths\n  if (length(item) != length(dataset$max))\n    return(FALSE)\n  \n  if (class(item) == \"numeric\") {\n    # If all item elements are numeric it is because:\n    # 1.- all his attributes are numeric\n    # 2.- categorical values are coded into a numeric number, this is how read.keel() do the reading of data.\n    all(item < dataset$max)\n    \n  } else {\n    # If not, we need to check every categorical value if they have valid values. This is slower than the former option.\n    catData <- which(dataset$atributeTypes == \"c\")\n    numData <-\n      which(dataset$atributeTypes == \"r\" | dataset$atributeTypes == \"e\")\n    \n    cvalues <- dataset$categoricalValues[catData]\n    cItem <- item[catData]\n    \n    #Check if categorical values of an item have got valid values.\n    values <- lapply(\n      X = seq_len(length(cItem)),\n      FUN = function(x, lista, items) {\n        any(lista[[x]] == items[x])\n      }, cvalues, cItem\n    )\n    values <- unlist(values)\n    \n    # If all values are valid, continue the process\n    if (!all(values)) {\n      return (FALSE)\n    }\n    \n    # Check numerical values\n    min <- dataset$min[numData]\n    max <- dataset$max[numData]\n    nItem <- as.numeric(item[numData])\n    \n    # If not all the elements are within the bounds, throw false.\n    if (!all(nItem >= min & nItem <= max)) {\n      return (FALSE)\n    }\n    \n    #Return, the element is ok.\n    TRUE\n    \n  }\n  \n  \n\n  \n}\n\n\n\n#' \n#' Reads an ARFF file\n#' \n#' This function reads an ARFF file and get the subyacent \\code{keel} object\n#'\n#' @param file The ARFF file to read.\n#' @param nLabels The number of fuzzy labels to generate. By default 3.\n#' \n#' \n#' @return a 'keel' object ready to use with the algorithms that are in the package\n#' \nkeelFromARFF <- function(file, nLabels = 3){\n  options(warn = -1)\n  conjunto <- read_arff(file)\n  \n\n  relation <- strsplit(conjunto[[1]], \" \")[[1]][2]\n  \n  #Make attribute names and types\n  atributeNames <- names(conjunto[[2]])\n  categoricos <- regmatches(x = conjunto[[2]], gregexpr(pattern = \"[/^{*}/$]\", text = conjunto[[2]]))\n  conjunto[[2]] <- gsub(pattern = \"[/^{*}/$]\", replacement = \"\", x = conjunto[[2]])\n  categoricos <- unlist(lapply(categoricos, function(x){length(x) > 0}))\n  types <- character(length(categoricos))\n  types[] <- \"r\"\n  types[which(categoricos)] <- \"c\"\n  \n  if(types[length(types)] != \"c\")\n    stop(\"Last value of the dataset is not categorical. We cannot create a dataset which class is not categorical.\")\n  \n  #Get min and max.\n  longitud_categoricos <- regmatches(x = conjunto[[2]], gregexpr(pattern = \"[[:alnum:]]*[^(,/$| */$)]\", text = conjunto[[2]]))\n  longitud <- unlist(lapply(longitud_categoricos, length))\n  values <- matrix(data = unlist(lapply(conjunto[[3]][,which(!categoricos)], \n                                        function(x){\n                                          x <- as.numeric(x)\n                                          c(min(na.exclude(x)), max(na.exclude(x)))\n                                          })),\n                   ncol = 2, byrow = TRUE)\n  min <- max <- numeric(length(categoricos))\n  min[which(!categoricos)] <- values[,1]\n  max[which(!categoricos)] <- values[,2]\n  max[which(categoricos)] <- longitud[which(categoricos)]\n \n  nVars <- NCOL(conjunto[[3]]) - 1\n  \n  class_names <- longitud_categoricos[[length(longitud_categoricos)]]\n  \n  #Examples per class\n  examplesClass <- unlist(lapply(longitud_categoricos[[length(longitud_categoricos)]], function(x, values){\n    sum(x == values)\n  }, conjunto[[3]][, NCOL(conjunto[[3]])]))\n  names(examplesClass) <- class_names\n  \n  #Ns\n  Ns <- NROW(conjunto[[3]])\n  #Lost Data\n  lostData <- FALSE\n  #Covered\n  covered <- logical(Ns)\n  #Categorical Values\n  longitud_categoricos[which(longitud <= 1)] <- NA\n  \n  #Fuzzy and crisp sets\n  fuzzySets <-\n    .create_fuzzyIntervals(\n      min = min, max = max, num_sets = nLabels, types = types\n    )\n  crispSets <- .createCrispIntervals(fuzzyIntervals = fuzzySets)\n  \n  #Conjuntos\n  conjuntos <-\n    .dameConjuntos(data_types = types, max = max, n_labels = nLabels)\n  \n  #DATA\n  if (Sys.info()[1] != \"Windows\")\n    data <-\n    parallel::mclapply(\n      X = as.data.frame(t(conjunto[[3]]), stringsAsFactors = FALSE), FUN = .processData, longitud_categoricos, types, TRUE, mc.cores = parallel::detectCores()\n    )\n  else\n    #In windows mclapply doesnt work\n    data <-\n    parallel::mclapply(\n      X = as.data.frame(t(conjunto[[3]])), FUN = .processData, longitud_categoricos, types, TRUE, mc.cores = 1\n    )\n  \n  lista <- list(\n    relation = relation,\n    atributeNames = atributeNames,\n    atributeTypes = types,\n    min = min,\n    max = max,\n    nVars = nVars,\n    data = data,\n    class_names = class_names,\n    examplesPerClass = examplesClass,\n    lostData = lostData,\n    covered = covered,\n    fuzzySets = fuzzySets,\n    crispSets = crispSets,\n    conjuntos = conjuntos,\n    categoricalValues = longitud_categoricos,\n    Ns = Ns\n  )\n  class(lista) <- \"keel\"\n  \n\n  options(warn = 0)\n  lista\n}\n\n\n#'\n#' Creates a \\code{keel} object from a \\code{data.frame}\n#' \n#' Creates a \\code{keel} object from a \\code{data.frame} and create fuzzy labels for numerical variables too.\n#' \n#' @param data A data.frame object with all neccesary information. See details.\n#' @param relation A string that indicate the name of the relation.\n#' @param nLabels The number of fuzzy labels to use. By default 3.\n#' @param names An optional character vector indicating the name of the attributes.\n#' @param types An optional character vector indicating 'c' if variable is categorical, 'r' if is real and 'e' if it is an integer\n#' @param classNames An optional character vector indicating the values of the target class.\n#' \n#' @details The information of the data.frame must be stored with instances in rows and variables in columns\n#' If you dont specify any of the optional parameter the function try to obtain them automatically. \n#' \n#' For \\code{'names'} if it is NA, the function takes the name of the columns by \\code{colnames}.\n#' \n#' For \\code{'types'} if it is NA, the function takes the type of an attribute asking the type of the column of the data.frame.\n#' If it is \\code{'character'} it is assumed that it is categorical, and if \\code{'numeric'} it is assumed that it is a real number.\n#' PLEASE, PAY ATTENTION TO THIS WAY OF WORK. It can cause tranformation errors taking a numeric variable as categorical or vice-versa.\n#' \n#' For \\code{'classNames'} if it is NA, the function returns unique values of the last attribute of the data.frame that is considered the class attribute.\n#' \n#' @return A \\code{keel} object with all the information of the dataset.\n#' \n#' @examples \n#' library(SDR)\n#' df <- data.frame(matrix(runif(1000), ncol = 10))\n#' #Add class attribute\n#' df[,11] <- c(\"0\", \"1\")\n#' keelObject <- keelFromDataFrame(df, \"random\")\n#' invisible()\n#' \n#' @seealso \\code{\\link{read.keel}}\n#' \n#' @author Angel M Garcia <amgv0009@@red.ujaen.es>\n#' \n#' @export\nkeelFromDataFrame <- function(data, relation, nLabels = 3, names = NA, types = NA, classNames = NA){\n  #check data.frame\n  if(! is.data.frame(data))\n    stop(paste(substitute(data), \"must be a data.frame\"))\n  #Create the data.frame without factors\n  data <- as.data.frame(data, stringsAsFactors = FALSE)\n  #Check if the last attribute (class attribute) is categorical\n  if(! is.character(.subset2(data, NCOL(data))))\n    stop(\"Last attribute of the dataset, that define the class attribute, must be categorical.\")\n  if(missing(relation))\n    relation <- substitute(data)\n  \n  #Checks parameters\n  checks <- is.na(c(names, types, classNames))\n  \n  if(checks[1]){\n    #Get names from colnames\n    names <- colnames(data)\n  }\n  \n  if(checks[2]){\n    #Try to get the type of the attributes.\n    types <- vapply(data, function(x){\n                            if(is.character(x)){\n                              'c'\n                            } else {\n                              'r'\n                            }\n                              }, character(1))\n  }\n  \n  if(checks[3]){\n    classNames <- unique(.subset2(data, NCOL(data)))\n  }\n  \n  #get Nvars and Ns\n  nVars <- NCOL(data) - 1\n  Ns <- NROW(data)\n  \n  #get min and max\n  min <- max <- numeric(nVars + 1)\n  matriz <- vapply(data, function(x){\n    if(is.numeric(x)){\n      c(min(na.exclude(x)), max(na.exclude(x)))\n    } else {\n      c(0, length(unique(x)))\n    }\n  }, numeric(2))\n  \n  matriz <- matrix(matriz, ncol = 2, byrow = TRUE)\n  min <- matriz[,1]\n  max <- matriz[,2]\n  \n\n  \n  \n  #Lost Data\n  lostData <- FALSE\n  #Covered\n  covered <- logical(Ns)\n  #Categorical Values\n  categoricalValues <- lapply(data, function(x){ if(is.character(x)) unique(x) else NA})\n  \n  #Examples per class\n  examplesClass <- unlist(lapply(categoricalValues[[length(categoricalValues)]], function(x, values){\n    sum(x == values)\n  }, .subset2(data, nVars + 1)))\n  names(examplesClass) <- classNames\n  \n  #Fuzzy and crisp sets\n  fuzzySets <-\n    .create_fuzzyIntervals(\n      min = min, max = max, num_sets = nLabels, types = types\n    )\n  crispSets <- .createCrispIntervals(fuzzyIntervals = fuzzySets)\n  \n  #Conjuntos\n  conjuntos <-\n    .dameConjuntos(data_types = types, max = max, n_labels = nLabels)\n  \n  #DATA\n  if(Ns > 150){\n  if (Sys.info()[1] != \"Windows\")\n    data <-\n    parallel::mclapply(\n      X = as.data.frame(t(data), stringsAsFactors = FALSE), FUN = .processData, categoricalValues, types, TRUE, mc.cores = parallel::detectCores()\n    )\n  else\n    #In windows mclapply doesnt work\n    data <-\n    parallel::mclapply(\n      X = as.data.frame(t(data), stringsAsFactors = FALSE), FUN = .processData, categoricalValues, types, TRUE, mc.cores = 1\n    )\n  } else {\n    data <-\n      lapply(\n        X = as.data.frame(t(data), stringsAsFactors = FALSE), FUN = .processData, categoricalValues, types, TRUE\n      )\n  }\n  lista <- list(\n    relation = relation,\n    atributeNames = names,\n    atributeTypes = types,\n    min = min,\n    max = max,\n    nVars = nVars,\n    data = data,\n    class_names = classNames,\n    examplesPerClass = examplesClass,\n    lostData = lostData,\n    covered = covered,\n    fuzzySets = fuzzySets,\n    crispSets = crispSets,\n    conjuntos = conjuntos,\n    categoricalValues = categoricalValues,\n    Ns = Ns\n  )\n  class(lista) <- \"keel\"\n  lista\n  \n  \n}\n\n",
    "created" : 1444982556552.000,
    "dirty" : false,
    "encoding" : "ISO8859-1",
    "folds" : "",
    "hash" : "3618178261",
    "id" : "CA4F22AA",
    "lastKnownWriteTime" : 1445009149,
    "path" : "E:/Escritorio/SDR/R/leerDatos.R",
    "project_path" : "R/leerDatos.R",
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "type" : "r_source"
}