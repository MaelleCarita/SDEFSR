{
    "contents" : "              #############################################################################\n              #                                                                           #\n              #                     R implementation for FuGePSD                          #\n              #                                                                           #\n              #       This file contains functions related with FuGePSD algorithm         #\n              #                                                                           #\n              # Reference: A fuzzy genetic programming-based algorithm for subgroup       #\n              # discovery and the application to one problem of pathogenesis of acute     #\n              # sore throat conditions in humans, Carmona, C.J., Ruiz-Rodado V., del      #\n              # Jesus M.J., Weber A., Grootveld M., Gonzalez P., and Elizondo D. ,        #\n              # Information Sciences, Volume 298, p.180-197, (2015)                       #\n              #                                                                           #\n              #       Written on R by: Angel M. Garcia <amgv0009@red.ujaen.es>            #\n              #############################################################################\n\n\n\n#'\n#' Creates a random general rule\n#' \n#' It creates a random general rule for a provided dataset with, at most, 50 %% of the variables.\n#' \n#' @param dataset The keel dataset where getting the data\n#' @param tnorm The T-norm to use: 0 -> minimum T-norm, 1 -> product T-norm\n#' @param tconorm The T-conorm to use: 0 -> maximum T-conorm, 1 -> Probabilistic sum t-conorm\n#' @param rule_weight The Rule Weighting method: 0 -> Wining Rule, 1 -> Normalized sum, 2 -> Arithmetic mean\n#' @param clase Integer specifying the creation of a rule for the given class number. By default \\code{'NULL'}, makes a rule with a random class in the consecuent.\n#' \n#' @return  A new \\code{'Rule'} object\n#' \ncreateNewRule <- function(dataset, tnorm, tconorm, rule_weight, clase = NULL ){\n  \n   regla <- structure( list(antecedent = list(),                 # Antecedent part of the rule\n                              clas = integer(1),                 # Consecuent\n                              weight = numeric(1),               # Weight associated with the rule\n                              raw_fitness = numeric(1),          # Raw Fitness associated to the rule\n                              penalized_fitness = numeric(1),    # Penalize Fitness of the rule after applying token competition\n                              t_norm = integer(1),               # T-norm used to compute compatibility degree\n                              t_conorm = integer(1),             # T-conorm used to compute compatibility degree\n                              ruleWeight = integer(1),           # Way of compute the weight of the rule\n                              level = integer(1),                # 1 for general rules, 2 for specific rules\n                              ideal = integer(1),                # Number of examples that this rule can seize\n                              evaluated = logical(1),            # indicate if the rule is evaluated or not.\n                              tokens = logical(dataset$Ns),      # used in token competition procedure.\n                              \n                              #Quality Measures\n                              qm_Cnf_n = numeric(1),             # Crisp Confidence\n                              qm_Cnf_f = numeric(1),             # Fuzzy Confidence\n                              qm_Sig = numeric(1),               # Significance\n                              qm_Sens = numeric(1),              # Sensitivity\n                              qm_Unus = numeric(1),              # Unusualness\n                              qm_Sup = numeric(1),               # Support\n                              qm_Cov = numeric(1),               # Coverage\n                              \n                              #Variables for ranking NSGA-II\n                              rank = integer(1),\n                              crowdingDistance = numeric(1)\n                    ),  \n                    class = \"Rule\")\n  \n  \n   # Select Randomly variables of the dataset to create the antecedent (maximum 50 % of the variables are selected)\n  numVarsOfRule <- ceiling(.randIntClosed(1,dataset$nVars) * 0.5)\n  variables <- sample(dataset$nVars, numVarsOfRule)\n  regla$antecedent <- lapply(variables, .createNewFuzzyAntecedent, dataset)\n  \n  \n  # Fill the rest of the data.\n  regla$t_norm <- tnorm\n  regla$t_conorm <- tconorm\n  regla$ruleWeight <- rule_weight\n  regla$level = 1L\n  \n  if(is.null(clase))\n    regla$clas <- sample(0:(length(dataset$class_names) - 1), 1)\n  else\n    if(length(dataset$class_names) - 1 <= clase & clase >= 0)\n      regla$clas <- clase\n    else\n      stop(\"Error when creating a new Rule: 'clase' is greater than te number of classes or is less than zero.\")\n  #Return \n  regla\n}\n\n\n\n\n#'\n#'\n#' Creates a random fuzzy antecedent for a specific variable\n#' \n#' @param  variable The position of the variable to use.\n#' @param dataset The keel dataset where the function takes the data.\n#' \n#' \n#' \n.createNewFuzzyAntecedent <- function(variable, dataset){\n  antecedent <- structure(list(labels = list(), \n                               max_label = integer(1), \n                               var = integer(1), \n                               operator = integer(1)),\n                            class = \"FuzzyAntecedent\")\n  \n  antecedent$var <- variable\n  \n  if(dataset$atributeTypes[variable] == \"c\"){\n    antecedent$max_label <- dataset$max[variable]\n  } else {\n    antecedent$max_label <- dataset$conjuntos[variable]\n  }\n  \n  \n  #Select the variable randomly\n\n    i <- sample(antecedent$max_label, size = 1)\n    antecedent$labels <- list(list(name = dataset$atributeNames[variable], value = i - 1))\n    antecedent$operator <- round(runif(1), digits = 0)\n\n  antecedent\n}\n\n\n\n\n\n\n#'\n#' Delete a random variable from a rule \n#' \n#' @param rule The rule to work with.\n#' \n#' @return A new rule with a random variable in the antecedent removed.\n#'\nRule.deleteVariable <- function(rule){\n  if(class(rule) == \"Rule\"){\n    #Select the variable to remove in the antecedent\n    variable <- .randIntClosed(1, length(rule$antecedent))\n    #Remove the antecedent\n    rule$antecedent <- rule$antecedent[- variable]\n    \n    #Reset the values, because it is a new rule\n    rule[c(3:5, 8,10, 13:19)] <- 0\n    rule$evaluated <- FALSE\n    rule$level <- 1L\n    \n  \n    #Return \n    rule\n  }\n}\n\n\n\n\n#'\n#'  Remove completely the antecedent part of a rule.\n#'  \n#'  @param rule The rule to where we want to remove the antecedent.\n#'  \n#'  @return A new rule with an empty antecedent\n#'  \nRule.clearAntecedent <- function(rule){\n  if(class(rule) == \"Rule\"){\n    #Remove antecedent part overwrittin by an empty list.\n    rule$antecedent <- list()\n    \n    #Reset the values, because it is a new rule\n    rule[c(3:5, 8,10, 13:19)] <- 0\n    rule$evaluated <- FALSE\n    rule$level <- 1L\n    \n    \n    \n    #Return\n    rule\n  }\n}\n\n\n#'\n#' Add a new random variable to the antecedent of the rule.\n#' \n#' @param rule The rule to work with.\n#' @param dataset The dataset to get the data.\n#' @return A new rule with an added variable.\n#'\nRule.addVariable <- function(rule, dataset){\n  if(class(rule) == \"Rule\"){\n    \n    nVars <- dataset$nVars\n    old_antecedent <- rule$antecedent\n    \n    if(length(old_antecedent) >= nVars){\n      stop(\"It is not possible to add new vars to this rule because it has all possible variables.\")\n    }\n    \n    # Get variables that are now in the rule.\n    selected <- logical(nVars)\n    selected[vapply(old_antecedent, function(x){x$var}, integer(1))] <- TRUE\n    \n    #From the not selected variables, we pick up one randomly\n    notSel <- which(!selected)\n    old_antecedent[[length(old_antecedent) + 1]] <- \n      .createNewFuzzyAntecedent(variable = notSel[.randIntClosed(1,length(notSel))],\n                               dataset = dataset)\n    rule$antecedent <- old_antecedent\n    \n    #RESET VALUES, it is a new rule\n    rule[c(3:5, 8,10, 13:19)] <- 0\n    rule$evaluated <- FALSE\n    rule$level <- 1L\n    \n    \n    \n    #Return\n    rule\n  }\n}\n  \n  \n  #'\n  #' Adds a new random label to the variable selected in the rule.\n  #' \n  #'  @param rule The rule to work with\n  #'  @param variable the selected variable (is the index of the list $antecedent of the rule)\n  #'  @param dataset, the dataset where getting all the data.\n  #'  \n  #'  @return the same rule but with the params reinitialized and marked as non evaluated.\n  #'  \n  Rule.addLabel <- function(rule, variable, dataset){\n    if(class(rule) == \"Rule\" & class(dataset) == \"keel\"){\n      \n      if(variable > length(rule$antecedent)){\n        stop(\"Can not add label to this rule. Variable used is grater than antecedent size.\")\n      }\n      \n      fuzzyAnt <- rule$antecedent[[variable]]\n      datasetVar <- fuzzyAnt$var\n      \n      selected <- logical(fuzzyAnt$max_label)\n      #Find a label that is not in the rule yet.\n      selected[fuzzyAnt[[1]][[1]][[2]]] <- TRUE\n      if(! all(selected)){\n         labelSelected <- sample(which(!selected), 1)\n        \n        #Add the label to the fuzzy Antecedent\n      \n          if(length(fuzzyAnt$labels) < 1){\n            fuzzyAnt$labels <- list(list(name = dataset$atributeNames[datasetVar], value = labelSelected - 1))\n          }\n     \n      }\n      \n      rule$antecedent[[variable]] <- fuzzyAnt\n      #Reset the values, because it is a new rule\n      rule[c(3:5, 8,10, 13:19)] <- 0\n      rule$evaluated <- FALSE\n      rule$level <- 1L\n      \n      \n      #return\n      rule\n    }\n  }\n  \n  \n  \n  \n  \n  #'\n  #' Change randomly a label associated to the rule with a non-existing label on the rule\n  #' \n  #'  @param rule The rule to work with\n  #'  @param variable the selected variable (is the index of the list $antecedent of the rule)\n  #'  \n  Rule.changeLabel <- function(rule, variable){\n    if(class(rule) == \"Rule\"){\n      if(variable > length(rule$antecedent)){\n        stop(\"Can not change Label. 'variable' is greater than antecedent length.\")\n      }\n      \n      fuzzyAnt <- rule$antecedent[[variable]]\n      selected <- logical(fuzzyAnt$max_label)\n      \n      #Find a label that is not in the rule yet.\n      if(length(fuzzyAnt$labels) > 0)\n        selected[fuzzyAnt[[1]][[1]][[2]] + 1] <- TRUE\n      \n      if(!all(selected)){\n        labelSelected <- sample(which(!selected), 1) - 1\n        #Select a label and change it.\n        fuzzyAnt[[1]][[1]][[2]] <- labelSelected\n      }\n      \n      rule$antecedent[[variable]] <- fuzzyAnt\n      #Reset the values, because it is a new rule\n      rule[c(3:5, 8,10, 13:19)] <- 0\n      rule$evaluated <- FALSE\n      rule$level <- 1L\n     \n      \n      #return\n      rule\n      \n    }\n  }\n  \n  \n  #'\n  #' Create a new rule by mixing the antecedent part of two rules.\n  #' \n  #' @param rule1 A rule\n  #' @param rule2 Another rule\n  #' \n  #' @return a list with the antecedents mixed. (This list would be the $antecedent part of another rule)\n  #' \n  Rule.exchangeVariables <- function(rule1, rule2){\n    if(class(rule1) == \"Rule\" & class(rule2) == \"Rule\"){\n      fuzzyAnt1 <- rule1$antecedent\n      fuzzyAnt2 <- rule2$antecedent\n      \n      #Select randomly variables from antecedent 1 and 2\n      if(length(fuzzyAnt1) > 1){\n        selected1 <- runif(length(fuzzyAnt1)) < 0.5\n      } else {\n        selected1 <- TRUE\n      }\n      \n      if(length(fuzzyAnt2) > 1){\n        selected2 <- runif(length(fuzzyAnt2)) < 0.5\n      } else {\n        selected2 <- TRUE\n      }\n      \n      #Mix this variables\n      fuzzyAnt1 <- fuzzyAnt1[selected1]\n      fuzzyAnt2 <- fuzzyAnt2[selected2]\n      \n      values1 <- vapply(fuzzyAnt1, function(x){x$var}, integer(1))\n      \n      # Forma muy INEFICIENTE !! \n      for(x in fuzzyAnt2){\n        found <- which(x$var == values1)\n        if(length(found) > 0){  # FuzzyAnt1 now has this variable. We try to mix them.\n            if(length(fuzzyAnt1[[found]][[1]]) < 1)\n              fuzzyAnt1[[found]][[1]][[1]] <- x[[1]][[1]]\n        } else {\n          fuzzyAnt1[[length(fuzzyAnt1) + 1]] <- x\n        }\n      }\n    \n      #Return \n      fuzzyAnt1\n    }\n  }\n  \n  \n  \n  #' \n  #'  Evaluate a single rule. \n  #'  \n  #'  @param rule The rule we want to evaluate (Class \"Rule\").\n  #'  @param dataset The keel dataset object with the examples to compare with the rule (Class \"keel\")\n  #'  @param data Matrix with the data of the dataset, one colum per rule. The data must not contain the last column, the class. (use .separar for this task and convert the list into a matrix)\n  #'  @param categoricalValues a logical vector indicating which attributes in the dataset are categorical\n  #'  @param numericalValues a logical vector indicating which attributes in the dataset are numerical\n  #'  @param t_norm The T-norm to use. 0 for minimum t-norm, 1 for product t-norm (default: 1)\n  #'  @param ruleWeight An integer with the rule weighting method. \\itemize{\n  #'         \\item 0 -> Classic Certainty Factor weight\n  #'         \\item 1 -> Penalized Certainty Factor weight II\n  #'         \\item 2 > Penalized Certainty Factor weight IV\n  #'         \\item 3 -> No Rule Weight\n  #'         }\n  #' @return The rule evaluated.\n  #' \n  Rule.evaluate <- function(rule, dataset, data, categoricalValues, numericalValues, t_norm = 1, ruleWeight = 0){\n    if(class(rule) == \"Rule\" & class(dataset) == \"keel\"){\n      if(! rule$evaluated){\n         #De momento probamos esto:\n        correctly_matching_examples_by_clas <- integer(length(dataset$class_names)) # For calculate significance\n        compatibility_matching_examples_by_clas <- numeric(length(dataset$class_names))\n        compatibility_matching_examples <- numeric(1)\n        matching_examples <- integer(1)\n        compatibility_correctly_matching_examples <- numeric(1)\n        correctly_matching_examples <- integer(1)\n        \n        #Get compatibility\n        perts <- .fitnessFuGePSD(regla = Rule.toCANVectorRepresentation(rule, dataset), \n                                 dataset = dataset, \n                                 noClass = data,\n                                 nLabels = dim(dataset$fuzzySets)[1], \n                                 max_regla = dataset$conjuntos,\n                                 cate = categoricalValues, \n                                 num = numericalValues,\n                                 t_norm = t_norm)\n       \n        \n        #Calculate covered examples.\n        covered <- which(perts > 0)  # Que pasa si no se cubre a ningun ejemplo?\n        classes <- unlist(.getClassAttributes(dataset$data[covered]))\n        correctly_matching_examples_by_clas[as.integer(names(table(classes + 1)))] <- table(classes + 1)\n        matching_examples <- length(covered)\n        compatibility_matching_examples <- sum(perts[covered])\n        \n        #Calculate compatibility per class (for rule weigth)\n        for(i in seq_len(length(classes))){\n          compatibility_matching_examples_by_clas[classes[i] + 1] <- compatibility_matching_examples_by_clas[classes[i] + 1] + perts[covered[i]]\n        }\n        \n        corr_covered <- covered[which(classes == rule$clas)]\n        compatibility_correctly_matching_examples <- sum(perts[corr_covered])\n        correctly_matching_examples <- length(corr_covered)\n        rule$ideal <- length(corr_covered)  #Number of ideal covered examples for token competition procedure\n        \n        #Mark tokens of the rule\n        rule$tokens <- logical(dataset[[16]])\n        rule$tokens[corr_covered] <- TRUE\n        \n        #Calculate quality measures\n        rule$qm_Cov <- matching_examples / dataset$Ns\n        rule$qm_Sup <- correctly_matching_examples / dataset$Ns\n        rule$qm_Sens <- correctly_matching_examples / dataset$examplesPerClass[[rule$clas + 1]]\n        if(matching_examples > 0){\n          rule$qm_Cnf_n <- correctly_matching_examples / matching_examples\n        } else {\n          rule$qm_Cnf_n <- 0\n        }\n        \n        if(compatibility_correctly_matching_examples > 0){\n          rule$qm_Cnf_f <- compatibility_correctly_matching_examples / compatibility_matching_examples\n        } else {\n          rule$qm_Cnf_f <- 0\n        }\n        \n        rule$qm_Unus <- rule$qm_Cov * (rule$qm_Cnf_n - (dataset$examplesPerClass[[rule$clas + 1]] / dataset$Ns))\n          \n        #Significance computation\n        by_class <- which(correctly_matching_examples_by_clas > 0)\n        values <- unlist(dataset$examplesPerClass[by_class])\n        rule$qm_Sig <- 2 * sum(correctly_matching_examples_by_clas[by_class] * log10(values / (values * rule$qm_Cov) ))\n        \n        #Assing fitness and weights\n        rule$raw_fitness <- rule$qm_Cnf_f\n        rule$penalized_fitness <- -1\n        \n        #Assign rule weight\n        if(ruleWeight == 0){ #Classis Certainty Factor weight\n          total <- sum(compatibility_matching_examples_by_clas)\n          if(total != 0){\n             rule$ruleWeight <- compatibility_matching_examples_by_clas[rule$clas + 1] / total\n          } else {\n            rule$ruleWeight <- 0\n          }\n        }  else if(ruleWeight == 1){ #Penalized Certainty Factor weight II\n          total <- sum(compatibility_matching_examples_by_clas)\n          if(total != 0){\n            suma <- (total - compatibility_matching_examples_by_clas[rule$clas + 1]) / (length(dataset$class_names) - 1)\n            rule$ruleWeight <- (compatibility_matching_examples_by_clas[rule$clas + 1] - suma) / total\n          } else {\n            rule$ruleWeight <- 0\n          }\n        } else if(ruleWeight == 2){ #Penalized Certainty Factor weight II\n          total <- sum(compatibility_matching_examples_by_clas)\n          if(total != 0){\n            suma <- total - compatibility_matching_examples_by_clas[rule$clas + 1] \n            rule$ruleWeight <- (compatibility_matching_examples_by_clas[rule$clas + 1] - suma) / total\n          } else {\n            rule$ruleWeight <- 0\n          }\n        } else {\n          rule$ruleWeight <- 1\n        }\n        #Set rule as evaluated\n        rule$evaluated <- TRUE\n      }\n      #Return\n      rule\n    }\n  }\n  \n  \n  \n  \n  #'\n  #' Converts a rule antecedent to a CANONICA vector representation\n  #' \n  #' The function converts a rule into a CANONICA vector representation for ease the evaluation.\n  #' The evaluation of a rule with a vetor representation can be evaluated througth functions\n  #' of evaluation of rule (.fit13 or .fitnessMESDIF) that are available inside the package SDR\n  #' \n  #' @param rule The rule that we want to evaluate.\n  #' @param dataset The keel dataset which rule refers to.\n  #' \n  #' @return a matrix with one column to use easily with fitness functions of this package\n  #' \n  Rule.toCANVectorRepresentation <- function(rule, dataset){\n    vector <- dataset$conjuntos\n    \n    vars <- vapply(rule$antecedent, function(x) x$var, integer(1))\n    values <- vapply(rule$antecedent, function(x) x$labels[[1]][[2]], numeric(1))\n    \n    \n    vector[vars] <- values\n    \n    as.matrix(vector)\n  }\n  \n  \n  #'\n  #' Performs tournament selection for the FuGePSD algorithm\n  #' \n  #' It makes a tournament selection for the FuGePSD algorithm with variable tournament size.\n  #' \n  #' @param pop The rule population\n  #' @param tamTournament The size of the tornament (>= 2)\n  #' \n  #' @return the index in \\code{'pop'} of the best individual in the tournament.\n  #' \n  tournamentSelection <- function(pop, tamTournament){\n    if(tamTournament < 2)\n      stop(\"'tamTournament' must be 2 or greater than 2.\")\n    \n    #select individuals of the populations\n    individuals <- sample(seq_len(length(pop)), size = tamTournament, replace = FALSE)\n    rawFitnessIndividuals <- vapply(pop[individuals], function(x, pop){x$raw_fitness}, numeric(1), pop)\n    \n    individuals[which(rawFitnessIndividuals == max(rawFitnessIndividuals))][1]\n  }\n  \n  #'\n  #' Perfom the mutation operator for FuGePSD algorithm.\n  #' \n  #' @param rule The rule object to be mutated.\n  #' @param dataset a keel object associated with the rule.\n  #' @return a new rule object with the rule mutated.\n  #'\n  FuGePSD_Mutation <- function(rule, dataset){\n \n    #select a random variable to mute.\n    variable <- .randInt(1, length(rule$antecedent))\n    \n    if(runif(1) < 0.5){\n      #Apply label adition\n      new_rule <- Rule.addLabel(rule = rule, variable = variable, dataset = dataset)\n    } else {\n      #Apply label change\n      new_rule <- Rule.changeLabel(rule, variable)\n    }\n    \n    #Return\n    new_rule\n  }\n  \n  #' \n  #' Performs the FuGePSD crossover function.\n  #' \n  #' @param rule1 a rule object\n  #' @param rule2 another rule object.\n  #' @param nvars number of variables in the dataset INCLUDING class variable.\n  #' @return a new rule object.\n  #'\n  FuGePSD_crossover <- function(rule1, rule2, nvars){\n    new_rule <- rule1\n    if( .randIntClosed(1, nvars) >= nvars ){\n      # Cutpoint in the class\n      new_rule$clas <- rule2$clas\n    } else {\n      # Cutpoint in the variables. \n      if(runif(1) < 0.5)\n        new_rule$antecedent <- Rule.exchangeVariables(rule1, rule2)\n    }\n    \n    #Reset values of new_rule, this is a new rule\n    new_rule[c(3:5, 8,10, 13:19)] <- 0\n    new_rule$evaluated <- FALSE\n    new_rule$level <- 1L\n   \n    \n    \n    #return \n    new_rule\n  }\n  \n  \n  \n  \n  #'\n  #' @title Fuzzy Genetic Programming-based learning for Subgroup Discovery (FuGePSD) Algorithm.\n  #' @description Make a subgroup discovery task using the FuGePSD algorithm.\n  #' \n  #' @param paramFile The path of the parameters file. \\code{NULL} If you want to use training and test \\code{keel} variables\n  #' @param training A \\code{keel} class variable with training data.\n  #' @param test A \\code{keel} class variable with test data.\n  #' @param output Character vector with the paths where store information file, rules file and test quality measures file, respectively. For rules and quality measures files, the algorithm generate 4 files, each one with the results of a given filter of fuzzy confidence.\n  #' @param seed An integer to set the seed used for generate random numbers.\n  #' @param t_norm A string with the t-norm to use when computing the compatibilty degree of the rules. Use \\code{'Minimum/Maximum'} to specify the minimum t-norm, if not, we use product t-norm that is the default method. \n  #' @param ruleWeight String with the method to calculate the rule weight. Possible values are: \n  #' \\itemize{\n  #'  \\item \\code{Certainty_Factor}: It uses the Classic Certainty Factor Weight method.\n  #'  \\item \\code{Average_Penalized_Certainty_Factor}: It uses Penalized Certainty Factor weight II by Ishibuchi.\n  #'  \\item \\code{No_Weights}: There are no weight calculation.\n  #'  \\item Default: If none of this are specificied, the default method is Penalized Certainty Factor Weight IV by Ishibuchi.\n  #'      }\n  #' @param frm A string specifying the Fuzzy Reasoning Method to use. Possible Values are:\n  #' \\itemize{\n  #'  \\item \\code{Normalized_Sum}: It uses the Normalized Sum or Additive Combination Fuzzy Reasoning Method.\n  #'  \\item \\code{Arithmetic_Mean}: It uses the Arithmetic Mean Fuzzy Reasoning Method.\n  #'  \\item Default: By default, Winning Rule Fuzzy Reasoning Method are selected.\n  #' }\n  #' @param numGenerations An integer to set the number of generations to perfom before stop the evolutionary process.\n  #' @param numberOfInitialRules An integer to set the number individuals or rules in the initial population.\n  #' @param crossProb Sets the crossover probability. We recommend a number in [0,1].\n  #' @param mutProb Sets the mutation probability. We recommend a number in [0,1].\n  #' @param insProb Sets the insertion probability. We recommend a number in [0,1].\n  #' @param dropProb Sets the dropping probability. We recommend a number in [0,1].\n  #' @param tournamentSize Sets the number of individuals that will be chosen in the tournament selection procedure. This number must be greater than or equal to 2.\n  #' @param globalFitnessWeights A numeric vector of length 4 specifying the weights used in the computation of the Global Fitness Parameter. \n  #' @param ALL_CLASS if TRUE, the algorithm returns, at least, the best rule for each target class, even if it does not pass the filters. If FALSE, it only returns, at least, the best rule if there are not rules that passes the filters.\n  #' \n  #' \n  #'  @details This function sets as target variable the last one that appear in the KEEL file or object. If you want \n  #'     to change the target variable, you can use \\link{changeTargetVariable} for this objective.  \n  #'     The target variable MUST be categorical, if it is not, throws an error.\n  #'     \n  #'     If you specify in \\code{paramFile} something distintc to \\code{NULL} the rest of the parameters are\n  #'     ignored and the algorithm tries to read the file specified. See \"Parameters file structure\" below \n  #'     if you want to use a parameters file.\n  #'     \n  #'  @return The algorithm shows in console the following results:\n  #'  \\enumerate{\n  #'    \\item Information about the parameters used in the algorithm.\n  #'    \\item Results for each filter:\n  #'      \\enumerate{\n  #'        \\item Rules generated that passes the filter.\n  #'        \\item The test quality measures for each rule in that filter.\n  #'      }\n  #'  }\n  #'  Also, this results are saved in a file with rules and other with the quality measures, one file per filter.\n  #'  \n  #'  @section How does this algorithm work?:\n  #'  This algorithm performs a EFS based on a genetic programming algorithm. This algorithm starts with an initial \n  #'  population generated in a random manner where individuals are represented through the \"chromosome = individual\"\n  #'  approach includind both antecedent and consequent of the rule. The representation of the consequent has the advantage\n  #'  of getting rules for all target class with only one execution of the algorithm.  \n  #'  \n  #'  The algorithm employs a cooperative-competition approach were rules of the population cooperate and compete between them in order to \n  #'  obtain the optimal solution. So this algorithm performs to evaluation, one for individual rules to competition and other for the total population \n  #'  for cooperation.  \n  #'  \n  #'  The algorithm evolves generating an offspring population of the same size than initial generated by the application of the\n  #'  genetic operators over the main population. Once applied, both populations are joined a token competition is performed in order to \n  #'  mantain the diversity of the rules generated. Also, this token competition reduce the population sice deleting those rules that are not competitive.  \n  #'  \n  #'  After the evolutionary process a screening function is applied over the best population. This screening function filter the rules that have a minimium\n  #'  level of confidence and sensitivity. Those levels are 0.6 for sensitivy and four filters of 0.6, 0.7, 0.8 and 0.9 for fuzzy confidence are performed.  \n  #'  \n  #'  Also, the user can force the algorithm return at least one rule for all target class values, even if not pass the screening function. This \n  #'  behaviour is specified by the ALL_CLASS parameter.\n  #'  \n  #'  \n  #'  @section Parameters file structure:\n  #'   The \\code{paramFile} argument points to a file which has the neccesary parameters to execute FuGePSD.\n  #'   This file \\strong{must} be, at least, this parameters (separated by a carriage return):\n  #'   \\itemize{\n  #'     \\item \\code{algorithm}  Specify the algorithm to execute. In this case. \"MESDIF\"\n  #'     \\item \\code{inputData}  Specify two paths of KEEL files for training and test. In case of specify only the name of the file, the path will be the working directory.\n  #'     \\item \\code{seed}  Sets the seed for the random number generator\n  #'     \\item \\code{nLabels}  Sets the number of fuzzy labels to create when reading the files\n  #'     \\item \\code{nEval}  Set the maximun number of \\strong{evaluations of rules} for stop the genetic process\n  #'     \\item \\code{popLength}  Sets number of individuals of the main population\n  #'     \\item \\code{eliteLength}  Sets number of individuals of the elite population. Must be less than \\code{popLength}  \n  #'     \\item \\code{crossProb}  Crossover probability of the genetic algorithm. Value in [0,1]\n  #'     \\item \\code{mutProb}  Mutation probability of the genetic algorithm. Value in [0,1]\n  #'     \\item \\code{Obj1} Sets the objetive number 1. \n  #'     \\item \\code{Obj2} Sets the objetive number 2. \n  #'     \\item \\code{Obj3} Sets the objetive number 3. \n  #'     \\item \\code{Obj4} Sets the objetive number 4.\n  #'     \\item \\code{RulesRep}  Representation of each chromosome of the population. \"can\" for canonical representation. \"dnf\" for DNF representation.\n  #'     \\item \\code{targetClass}  Value of the target variable to search for subgroups. The target variable \\strong{is always the last variable.} Use \\code{null} to search for every value of the target variable\n  #'   }\n  #'   \n  #'   An example of parameter file could be:\n  #'  \\preformatted{\n  #'  algorithm = FUGEPSD\n  #'  inputData = \"banana-5-1tra.dat\" \"banana-5-1tst.dat\"\n  #'  outputData = \"Parameters_INFO.txt\" \"Rules.txt\" \"TestMeasures.txt\"\n  #'  seed = 23783\n  #'  Number of Labels = 3\n  #'  T-norm/T-conorm for the Computation of the Compatibility Degree = Normalized_Sum\n  #'  Rule Weight = Certainty_Factor\n  #'  Fuzzy Reasoning Method = Normalized_Sum\n  #'  Number of Generations = 300\n  #'  Initial Number of Fuzzy Rules = 100\n  #'  Crossover probability = 0.5\n  #'  Mutation probability = 0.2\n  #'  Insertion probability = 0.15\n  #'  Dropping Condition probability = 0.15\n  #'  Tournament Selection Size = 2 \n  #'  Global Fitness Weight 1 = 0.7\n  #'  Global Fitness Weight 2 = 0.1 \n  #'  Global Fitness Weight 3 = 0.05\n  #'  Global Fitness Weight 4 = 0.2\n  #'  All Class = true}\n  #'\n  #' @references \n  #' A fuzzy genetic programming-based algorithm for subgroup discovery and the application to one problem of pathogenesis of acute sore throat conditions in humans, Carmona, C.J., Ruiz-Rodado V., del Jesus M.J., Weber A., Grootveld M., Gonzalez P., and Elizondo D. , Information Sciences, Volume 298, p.180-197, (2015)    \n  #'  \n  #' @examples \n  #' FUGEPSD(training = habermanTra,\n  #'          test = habermanTst,\n  #'          output = c(\"parametersFile.txt\", \"rulesFile.txt\", \"testQM.txt\"),\n  #'          seed = 23783,\n  #'          t_norm = \"Minimum/Maximum\",\n  #'          ruleWeight = \"Certainty_Factor\",\n  #'          frm = \"Normalized_Sum\",\n  #'          numGenerations = 20,\n  #'          numberOfInitialRules = 15,\n  #'          crossProb = 0.5,\n  #'          mutProb = 0.2,\n  #'          insProb = 0.15,\n  #'          dropProb = 0.15,\n  #'          tournamentSize = 2,\n  #'          globalFitnessWeights = c(0.7, 0.1, 0.3, 0.2),\n  #'          ALL_CLASS = TRUE)\n  #' \\dontrun{\n  #' Execution with a parameters file called 'ParamFile.txt' in the working directory:\n  #' \n  #' FUGEPSD(\"ParamFile.txt\")\n  #' \n  #' }\n  #' \n  #' @author Written on R by Angel M. Garcia <amgv0009@@red.ujaen.es>\n  #'  \n  #' @export\n  #' \n  FUGEPSD <- function(paramFile = NULL,\n                      training = NULL,\n                      test = NULL,\n                      output = c(\"optionsFile.txt\", \"rulesFile.txt\", \"testQM.txt\"),\n                      seed = 0,\n                      t_norm = \"product_t-norm\",\n                      ruleWeight = \"Certainty_Factor\",\n                      frm = \"Normalized_Sum\",\n                      numGenerations = 300,\n                      numberOfInitialRules = 100,\n                      crossProb = 0.5,\n                      mutProb = 0.2,\n                      insProb = 0.15,\n                      dropProb = 0.15,\n                      tournamentSize = 2,\n                      globalFitnessWeights = c(0.7, 0.1, 0.05, 0.2),\n                      ALL_CLASS = TRUE\n                      ){\n    #Catch start time\n    init_time <- as.numeric(Sys.time())\n    \n    if(is.null(paramFile)){\n      #Generate our parameters file\n      if(class(training) != \"keel\" | class(test) != \"keel\")\n        stop(\"Training or test or both object must be 'keel' class.\")\n      if(training[[1]] != test[[1]] )\n        stop(\"datasets ('training' and 'test') does not have the same relation name.\")\n      if(length(output) != 3 )\n        stop(\"You must specify three files to save the results.\")\n      if(length(globalFitnessWeights) != 4)\n        stop(\"'globalFitnessWeights' must be a length 4 vector.\")\n      if(tournamentSize < 2)\n        stop(\"'tournamentSize' must be greater than or equal to 2.\")\n      parametros <- list(algorithm = \"FUGEPSD\", \n                    inputData = c(as.character(substitute(training)), as.character(substitute(test))),\n                    outputData = output, \n                    seed = seed, \n                    nLabels = dim(training$fuzzySets)[1], \n                    nGens = numGenerations, \n                    popLength = numberOfInitialRules, \n                    crossProb = crossProb, \n                    mutProb = mutProb,\n                    insPro = insProb,\n                    dropProb = dropProb,\n                    frm = tolower(frm),\n                    tnorm = tolower(t_norm),\n                    ruleWeight = tolower(ruleWeight),\n                    tournamentSize = tournamentSize,\n                    allClass = ALL_CLASS,\n                    alphaFitness = 0,\n                    executionType = 1,\n                    gfw1 = globalFitnessWeights[1],\n                    gfw2 = globalFitnessWeights[2],\n                    gfw3 = globalFitnessWeights[3],\n                    gfw4 = globalFitnessWeights[1])\n      \n      #Print parameters in console\n      printFuGePSDParameters(parametros, training, FALSE)\n    } else {\n      #Start of the algorithm\n      parametros <- .read.parametersFile2(paramFile)\n      \n      training <- read.keel(parametros$inputData[1], parametros$nLabels)\n      test <- read.keel(parametros$inputData[2], parametros$nLabels)\n      \n      #Print parameters in console\n      printFuGePSDParameters(parametros, training, FALSE)\n    }\n    \n    #Check if the last variable is categorical.\n    if(training$atributeTypes[length(training$atributeTypes)] != 'c' | test$atributeTypes[length(test$atributeTypes)] != 'c')\n      stop(\"Target variable is not categorical.\")\n    \n    #Set the number of fuzzy labels\n    training <- modifyFuzzyCrispIntervals(training, nLabels)\n    training$conjuntos <- .dameConjuntos(data_types = training$atributeTypes, max = training$max, n_labels = nLabels)\n    test <- modifyFuzzyCrispIntervals(test, nLabels)\n    test$conjuntos <- .dameConjuntos(data_types = test$atributeTypes, max = test$max, n_labels = nLabels)\n    #Set Covered\n    #training$covered <- logical(training$Ns)\n    test$covered <- logical(test$Ns)\n    \n    categorical <- training$atributeTypes == \"c\"\n    categorical <- categorical[-length(categorical)]\n    numerical <- !categorical\n    \n    #Parse parameters\n    \n    if(parametros$tnorm == \"minimum/maximum\"){\n      parametros$tnorm = 0\n    } else {\n      parametros$tnorm = 1\n    }\n    \n    if(parametros$ruleWeight == \"certainty_factor\"){\n      parametros$ruleWeight <- 0\n    } else if(parametros$ruleWeight == \"average_penalized_certainty_factor\"){\n      parametros$ruleWeight <- 2\n    } else if(parametros$ruleWeight == \"no_weights\"){\n      parametros$ruleWeight <- 3\n    } else {\n      parametros$ruleWeight <- 1\n    }\n    \n    if(parametros$frm == \"normalized_sum\"){\n      parametros$frm <- 1\n    } else if(parametros$frm == \"arithmetic_mean\") {\n      parametros$frm <- 2\n    } else {\n      parametros$frm <- 0\n    }\n    set.seed(parametros$seed)\n    \n    cat(\"\\n\\nSearching Rules for all classes...\\n\\n\")\n    \n    #Execute the genetic algorithm\n    pop <- .gaFuGePSD(type = parametros[[18]],\n               dataset = training,\n               selection = tournamentSelection,\n               mutation = FuGePSD_Mutation,\n               crossover = FuGePSD_crossover,\n               popSize = parametros[[7]],\n               pcrossover = parametros[[8]],\n               pmutation = parametros[[9]],\n               pinsertion = parametros[[10]],\n               pdropping = parametros[[11]],\n               selectionSize = parametros[[15]],\n               AllClass = as.logical(parametros[[16]]),\n               T_norm = parametros[[13]],\n               ruleWeight = parametros[[14]],\n               frm = parametros[[12]],\n               maxiter = parametros[[6]],\n               weightsGlobalFitness = c(parametros[[19]], parametros[[20]], parametros[[21]], parametros[[22]]),\n               seed = parametros[[4]])\n    \n    \n    AllClass <- as.logical(parametros[[16]])\n    exampleClass <- unlist(.getClassAttributes(test$data))\n    datasetNoClass <- matrix(unlist(.separar(test)), nrow = test$nVars, ncol = test$Ns)\n    \n    ###################\n    #  TESTING RULES  #\n    ###################\n    \n    \n    #Now we have the best population obtained by the evolutionary process. Then, we apply 0.6, 0.7, 0.8 and 0.9\n    #filters of fuzzy confidence.\n    bestPop <- pop[[1]]\n    lapply(seq_len(length(bestPop)), function(x){bestPop[[x]]$evaluated <<- FALSE; invisible()})\n    classes <- vapply(bestPop, function(x){x$clas}, integer(1)) + 1L\n    filtros <- c(0.6, 0.7, 0.8, 0.9)\n    \n    #SCREENING FUNCTION\n   for(f in filtros){\n     examples_class <- logical(length(training$class_names))\n     pasan_filtro <- which(pop[[2]] >= f & pop[[3]] >= 0.6)\n     new_pop <- bestPop[pasan_filtro]\n     \n     if(length(new_pop) > 0){\n       examples_class[classes[pasan_filtro]] <- TRUE\n     }\n     \n     if(!all(examples_class) & AllClass){\n       cl <- which(!examples_class)\n       cl <- which(classes %in% cl)\n       pos <- which(pop[[3]][cl] >= 0.6)\n       posi <- na.exclude(pmatch(which(!examples_class), classes[pos]))\n       if(length(posi) > 0){\n         new_pop[(length(new_pop) + 1):(length(new_pop) + length(posi))] <- bestPop[pos[posi]]\n         examples_class[classes[pos[posi]]] <- TRUE\n       }\n     }\n     \n     #Verify the use of parameter ALL_CLASS\n     if(AllClass){\n       if(!all(examples_class)){\n       #As the bestPop is ordered by fuzzy confidence, we take the best rule in terms of confidence for \n       #each class that are not in the new population yet.\n       pos <- na.exclude(pmatch(which(!examples_class), classes))\n       new_pop[(length(new_pop) + 1):(length(new_pop) + length(pos))] <- bestPop[pos]\n       }\n     } else {\n       #If ! ALL_CLASS and new_pop is empty, the algorithm returns the best of the population.\n       if(length(new_pop) == 0){\n         new_pop[[1]] <- bestPop[[1]]\n       }\n     }\n     \n     #Order new_pop by class\n     new_classes <- vapply(new_pop, function(x){x$clas}, integer(1))\n     new_pop <- new_pop[order(new_classes)]\n     \n     #Evalute population against test data\n     testGlobalFitness <- Pop.evaluate(pop = bestPop, dataset = test, examplesNoClass = datasetNoClass, exampleClass = exampleClass, frm = parametros[[12]], categorical = categorical, numerical = numerical, t_norm = parametros[[13]], weights = c(parametros[[19]], parametros[[20]], parametros[[21]], parametros[[22]]) )\n     new_pop <- lapply(new_pop, Rule.evaluate, test, datasetNoClass, categorical, numerical, parametros[[13]], parametros[[14]])\n     \n     #Print results in files.\n     contador <- 1\n     \n     #Change the name of the output file by the following: $fileName$_filtro_AllClass.txt for rules file with filter 'filtro'\n     #                                                     $fileName$_filtro_AllClass_QM.txt\n     ruleFileName <- paste(substr(parametros$outputData[2], 1, regexpr(\"\\\\.[^\\\\.]*$\", parametros$outputData[2]) - 1),\n                                \"_f\", paste(substr(as.character(f), 1, 1) , substr(as.character(f), 3, 3) , sep = \"\"), \"_\", \n                                AllClass, \".txt\", sep = \"\")\n     \n     testQMFileName <- paste(substr(parametros$outputData[2], 1, regexpr(\"\\\\.[^\\\\.]*$\", parametros$outputData[2]) - 1),\n                           \"_f\", paste(substr(as.character(f), 1, 1) , substr(as.character(f), 3, 3) , sep = \"\"), \"_\", \n                           AllClass, \"_QM\", \".txt\", sep = \"\")\n      \n      cat(\"\\n\\n---- FILTER: \", f, \" ----\\n\\n\", sep = \"\")\n     \n      writeRuleFile(new_pop, training, ruleFileName)\n      cat(\"\\n QUALITY MEASURES OF THE RULES GENERATED: \\n\\n\")\n      writeTestQMFile(new_pop, testQMFileName, test$Ns)\n   \n   }\n   \n   cat(\"\\n\\nAlgorithm finished. \\nExecution time: \", parseTime(as.numeric(Sys.time()), init_time),  \"\\n\\n\", sep = \"\")\n    \n  }\n  \n  \n#'\n#' Calcultes the Fuzzy Reasoning Method for all examples for a given rule population\n#' \n#' @param pop A list with all rule object that define the population\n#' @param dataset the keel object with the dataset information.\n#' @param examplesNoClass matrix with all examples of the dataset without the class attribute. One examples per column.\n#' @param frm An integer specifing the tipo of fuzzy reasoning method to use. 0 for Winning Rule, 1 for Normalized Sum and 2 for Arithmetic Mean.\n#' @param categorical Logical vector indicating which attributes of the dataset are categorical.\n#' @param numerical Logical vector indicating which attributes of the dataset are numerical.\n#' @param t_norm The t_norm to use. 0 for minimum t-norm. 1 for product t-norm.\n#' \n#' @return a vector indicating the class predicted for each example.\n#'\nPop.fuzzyReasoningMethod <- function(pop, dataset, examplesNoClass, frm, categorical, numerical, t_norm){\n  reglas <- lapply(X = pop, Rule.toCANVectorRepresentation, dataset)\n  \n  #Calculate compatibility of all examples with all rules.\n  perts <- lapply(X = reglas,FUN = .fitnessFuGePSD, dataset, examplesNoClass, dim(dataset$fuzzySets)[1], dataset$conjuntos, categorical, numerical, t_norm)\n  #Multiply this compatibilty with the ruleWeight\n  pesos <- vapply(X = pop, function(x){x$ruleWeight}, numeric(1))\n  perts <- lapply(X = seq_len(length(pop)), FUN = function(x, lista, weights){lista[[x]] * weights[x]}, perts, pesos)\n  \n  df <- as.data.frame(matrix(unlist(perts), nrow = length(pop)))\n  \n  if(frm == 1){ #Normalized Sum\n    class_degrees <- numeric(length(dataset$class_names))\n    classes <- integer(dim(df)[2])\n    ejemplo <- 1\n    for(i in df){ #For each example\n      cont <- 1\n      for(j in i){ #For each rule\n        class_degrees[pop[[cont]]$clas + 1] <-  class_degrees[pop[[cont]]$clas + 1] <- class_degrees[pop[[cont]]$clas + 1] + .subset2(df, c(ejemplo, cont))\n        cont <- cont + 1\n      }\n      classes[ejemplo] <- which(class_degrees == max(class_degrees))[1] - 1\n      ejemplo <- ejemplo + 1\n    }\n    \n    #Return\n    classes\n    \n  } else if(frm == 2) {  #Arithmetic Mean\n    \n    class_degrees <- numeric(length(dataset$class_names))\n    \n    #Count of numbers of rules which have a class name.\n    class_cont <- integer(length(dataset$class_names))\n    names(class_cont) <- dataset$class_names\n    cuenta <- table(vapply(pop, function(x){x$clas}, integer(1)))\n    class_cont[as.integer(names(cuenta)) + 1] <- cuenta\n    \n    #Count the sumatory of rules.\n    classes <- integer(dim(df)[2])\n    ejemplo <- 1\n    for(i in df){ #For each example\n      cont <- 1\n      for(j in i){ #For each rule\n        class_degrees[pop[[cont]]$clas + 1] <- class_degrees[pop[[cont]]$clas + 1] + .subset2(df, c(ejemplo, cont))\n        cont <- cont + 1\n      }\n      class_degrees <- class_degrees / class_cont\n      classes[ejemplo] <- which(class_degrees == max(class_degrees))[1] - 1\n      ejemplo <- ejemplo + 1\n      class_degrees[] <- 0\n    }\n    \n    #Return\n    classes\n  } else { #Wining rule\n  \n    #For each example, we take the maximum compatibility degree and take the class associated with the rule with maximum compatibility\n    classes <- vapply(X = df, FUN = function(x){which(x == max(x))[1]}, integer(1))\n    \n    #Return\n    vapply(X = classes, function(x, popu){popu[[x]]$clas}, integer(1), pop) - 1\n  }\n  \n}\n  \n\n#'\n#'  Evaluates the entire population for the Global Fitness computation procedure.\n#'  \n#'  @param pop A list of 'Rule' objects.\n#'  @param dataset A 'keel' object with all the information of the dataset we are working\n#'  @param examplesNoClass Matrix with the data of the dataset, one colum per rule. The data must not contain the last column, the class. (use .separar for this task and convert the list into a matrix)\n#'  @param exampleClass Vector with the classes of all examples of the dataset\n#'  @param frm An integer specifing the tipo of fuzzy reasoning method to use. 0 for Winning Rule, 1 for Normalized Sum and 2 for Arithmetic Mean.\n#'  @param categorical A logical vector indicating which attributes of the dataset are categorical.\n#'  @param numerical A logical vector indicating which attributes of the dataset are numerical.\n#'  @param t_norm An integer specifying the t-norm to use. 0 for minimum t_norm, other value for product t-norm.\n#'  @param weights A numeric vector of length 4 indicating the weights used to calculate the global fitness of this population.\n#'  \n#'  @return A number which indicate the global fitness for this population.\n#'  \nPop.evaluate <- function(pop, dataset, examplesNoClass, exampleClass, frm, categorical, numerical, t_norm, weights){\n  nLabels <- dim(dataset$fuzzySets)[1]\n  \n  prediccion <- Pop.fuzzyReasoningMethod(pop, dataset, examplesNoClass, frm, categorical, numerical, t_norm)\n  \n  hits <- integer(1)\n  hitsPerClass <- vapply(X = seq_len(length(dataset$class_names)) - 1, FUN = function(x, prediccion, exampleClass){sum(exampleClass == prediccion & exampleClass == x)}, numeric(1), prediccion, exampleClass)\n  #Compute accuracy\n  accuracy <- sum(hitsPerClass / unlist(dataset$examplesPerClass))\n  accuracy <- accuracy / length(dataset$class_names)\n  \n  #Compute the average number of variables and conditions\n  num_var <- num_cond <- sum(vapply(X = pop, FUN = function(x){length(x$antecedent)}, numeric(1)))\n  ave_var <- num_var / length(pop)\n  ave_cond <- num_cond / length(pop)\n  \n  #Normalize values\n  norm_var <- (ave_var - 1) / (dataset$nVars - 1)\n  norm_cond <- (ave_cond - 1) / ((dataset$nVars * (nLabels - 1)) - 1)\n  norm_rul <- (length(pop) - length(dataset$class_names)) / (dataset$Ns - length(dataset$class_names))\n  \n  #Compute Global fitness and \n  weights[1] * accuracy + weights[2] * (1 - norm_var) + weights[4] * (1 - norm_rul)\n}\n  \n\n\n\n\n#'\n#' Runs a token competition procedure.\n#' \n#' @param pop A list of 'Rule' objects.\n#' @param dataset A 'keel' object with all the information about the dataset we are working.\n#' \n#' @return A list of 'Rule' objects with that rules that pass this token competition procedure.\n#' \ntokenCompetition <- function(pop, dataset){\n  \n  #Order pop by raw fitness\n  fitness <- vapply(pop, function(x){x$raw_fitness}, numeric(1))\n  pop <- pop[order(fitness, decreasing = TRUE)]\n  \n  #Empty tokens are false initialy\n  tokens <- logical(dataset$Ns)\n  \n  #Update penalized fitness value for all the population (Token competition procedure)\n  pos <- 1\n  for(i in pop){\n    count <- 0\n    if(i$ideal == 0){\n        i$penalize_fitness <- 0\n    } else {\n      cubre <- i$tokens & !tokens\n      tokens[which(cubre)] <- TRUE\n      count <- sum(cubre)\n      \n      i$penalized_fitness <- i$raw_fitness * (count / i$ideal)\n    }\n    pop[[pos]] <- i\n    pos <- pos + 1\n  }\n  \n  #Now, we delete the individuals with penalized fitness equal to 0\n  fitness <- vapply(pop, function(x){x$penalized_fitness}, numeric(1))\n  \n  #Return the populations with deleted individuals\n  pop[which(fitness > 0)]\n}\n\n\n\n\n\n#'\n#' Writes rules into a human-readable format into a file.\n#'\n#' @param pop A list of 'Rule' objects with the population we want to save.\n#' @param dataset A 'keel' object with all the information about the dataset the rules are pointing.\n#' @param fileName String with the path to store the rules.\n#' \n#' @details \n#' This function overwrites if the file specified by \\code{fileName} exists. Be careful!\n#' \nwriteRuleFile <- function(pop, dataset, fileName){\n  contador <- 1\n  RulesLine <- \"\"\n  sumVars <- 0\n  numRules <- length(pop)\n  \n  for(regla in pop){\n     #Make the human-readable rule representation\n     ruleRep <- sapply(regla$antecedent, function(x){paste(x$labels[[1]]$name, \" IS L_\", x$labels[[1]]$value, sep = \"\")})\n     ruleRep <- paste(ruleRep, collapse = \" AND \")\n     RulesLine <- paste(RulesLine, contador,\": IF \", ruleRep, \" THEN \", dataset$class_names[regla$clas + 1], \" with Rule Weight: \", regla$ruleWeight, \"\\n\", sep = \"\")\n     sumVars <- sumVars + length(regla$antecedent)\n     contador <- contador + 1\n  }\n  \n  finalLine <- paste(\"@Number of rules: \", numRules, \"\\n@Average number of variables: \", round(sumVars / numRules, 2), \"\\n\\n\", RulesLine, sep = \"\")\n  \n  cat(finalLine) #Prints in the console\n  cat(finalLine, file = fileName) #Prints in the file\n  \n  invisible()\n}\n\n#'\n#' Writes rules into a human-readable format into a file.\n#'\n#' @param pop A list of 'Rule' objects with the population we want to save.\n#' @param fileName String with the path to store the rules.\n#' @param numExamples An integer with the number of examples in the test file.\n#' \n#' @details \n#' This function overwrites if the file specified by \\code{fileName} exists. Be careful!\n#' \nwriteTestQMFile <- function(pop, fileName, numExamples){\n  #Get classes of the rules.\n  sum_nVars <- numeric(1)\n  sum_Cov <- numeric(1)\n  sum_Sig <- numeric(1)\n  sum_Unus <- numeric(1)\n  sum_Sens <- numeric(1)\n  tokens <- logical(numExamples)  #For total Support Calculation.\n  sum_ConfN <- numeric(1)\n  sum_ConfF <- numeric(1)\n  \n  nRules <- length(pop)\n  contador <- 1\n  Salida <- \"\"\n  for(regla in pop){\n    sum_nVars <- sum_nVars + length(regla$antecedent)\n    sum_Cov <- sum_Cov + regla$qm_Cov\n    sum_Sig <- sum_Sig + regla$qm_Sig\n    sum_Unus <- sum_Unus + regla$qm_Unus\n    sum_Sens <- sum_Sens + regla$qm_Sens\n    sum_ConfN <- sum_ConfN + regla$qm_Cnf_n\n    sum_ConfF <- sum_ConfF + regla$qm_Cnf_f\n    \n    tokens[which(regla$tokens)] <- TRUE\n    \n   #Rule QM\n   Salida <-  paste(Salida, paste(\"Rule \", contador, \":\", sep = \"\"),\n         paste(\"\\t - N_vars:\", length(regla$antecedent), sep = \" \"),\n         paste(\"\\t - Coverage:\", round(regla$qm_Cov, 6), sep = \" \"),\n         paste(\"\\t - Significance:\", round(regla$qm_Sig, 6), sep = \" \"),\n         paste(\"\\t - Unusualness:\", round(regla$qm_Unus, 6), sep = \" \"),\n         paste(\"\\t - Sensitivity:\", round(regla$qm_Sens, 6), sep = \" \"),\n         paste(\"\\t - Support:\", round(regla$qm_Sup, 6), sep = \" \"),\n         paste(\"\\t - FConfidence:\", round(regla$qm_Cnf_f,6), sep = \" \"),\n         paste(\"\\t - CConfidence:\", round(regla$qm_Cnf_n, 6), sep = \" \"),\n         sep = \"\\n\"\n    )\n   contador <- contador + 1\n  }\n  \n  #Global \n  Salida <- paste(Salida, \"Global:\",\n       paste(\"\\t - N_rules:\", nRules, sep = \" \"),\n       paste(\"\\t - N_vars:\", round(sum_nVars / nRules, 6), sep = \" \"),\n       paste(\"\\t - Coverage:\", round(sum_Cov / nRules, 6), sep = \" \"),\n       paste(\"\\t - Significance:\", round(sum_Sig / nRules, 6), sep = \" \"),\n       paste(\"\\t - Unusualness:\", round(sum_Unus / nRules, 6), sep = \" \"),\n       paste(\"\\t - Sensitivity:\", round(sum_Sens / nRules, 6), sep = \" \"),\n       paste(\"\\t - Support:\", round(sum(tokens) / numExamples, 6), sep = \" \"),\n       paste(\"\\t - FConfidence:\", round(sum_ConfF / nRules, 6), sep = \" \"),\n       paste(\"\\t - CConfidence:\", round(sum_ConfN / nRules, 6), sep = \" \"),\n       sep = \"\\n\"\n  )\n  #Print exit\n  cat(Salida) # On console\n  cat(Salida, file = fileName) #On file.\n  \n  invisible()\n  }\n\n\n\n\n#'\n#' Prints parameters information aboute the execution of the algorithm in console and in the output file \n#' specified by this parameters.\n#' \n#' @param parameters A list with all neccesary parameters.\n#' @param dataset A \\code{keel} object with all the information about the dataset.\n#' @param inputFromFiles A logical indicating if the input datasets are given from a file or from an object in the R environment.\n#' \nprintFuGePSDParameters <- function(parameters, dataset, inputFromFiles = TRUE){\n  line <- paste(\"\\n------------------------------------------------------\\n\", \n      \"Algorithm: FuGePSD\\n\",\n      \"Relation: \", dataset[[1]], \"\\n\",\n      \"Training file: \", parameters$inputData[1], if(!inputFromFiles) \" object\\n\",\n      \"Test file: \", parameters$inputData[2], if(!inputFromFiles) \" object\\n\",\n      \"Seed: \", parameters$seed, \"\\n\",\n      \"Number of Labels: \", parameters$nLabels, \"\\n\",\n      \"Number of Generations: \", parameters$nGens, \"\\n\",\n      \"Initial Number of Rules: \", parameters$popLength, \"\\n\",\n      \"Crossover Probability: \", parameters$crossProb, \"\\n\",\n      \"Mutation Probability: \", parameters$mutProb, \"\\n\",\n      \"Insertion Probability: \", parameters$insPro, \"\\n\",\n      \"Dropping Condition Probability: \", parameters$dropProb, \"\\n\",\n      \"Fuzzy Reasoning Method: \", parameters$frm, \"\\n\",\n      \"T-norm/T-conorm for the Computation of the Compatibility Degree: \", parameters$tnorm, \"\\n\",\n      \"Rule Weight: \", parameters$ruleWeight, \"\\n\",\n      \"Tournament Selection Size: \", parameters$tournamentSize, \"\\n\",\n      \"Global Fitness Weight 1: \", parameters$gfw1, \"\\n\",\n      \"Global Fitness Weight 2: \", parameters$gfw2, \"\\n\",\n      \"Global Fitness Weight 3: \", parameters$gfw3, \"\\n\",\n      \"Global Fitness Weight 4: \", parameters$gfw4, \"\\n\",\n      \"All Class: \", parameters$allClass, \"\\n\",\n      \"-----------------------------------------------------------\\n\\n\", sep = \"\")\n \n  cat(line)  #Print in console\n  cat(line, file = parameters$outputData[1])\n  \n}\n",
    "created" : 1445169735235.000,
    "dirty" : false,
    "encoding" : "ISO8859-1",
    "folds" : "",
    "hash" : "2708455295",
    "id" : "FFF70031",
    "lastKnownWriteTime" : 1445170969,
    "path" : "E:/Escritorio/SDR/R/FuGePSD.R",
    "project_path" : "R/FuGePSD.R",
    "properties" : {
    },
    "relative_order" : 10,
    "source_on_save" : false,
    "type" : "r_source"
}